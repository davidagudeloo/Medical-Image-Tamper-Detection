{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "18baeab2",
   "metadata": {},
   "source": [
    "# üß† Extracci√≥n de Caracter√≠sticas\n",
    "\n",
    "## üìù Descripci√≥n\n",
    "Este notebook corresponde a la **segunda fase del pipeline** para la detecci√≥n de im√°genes m√©dicas manipuladas. Aqu√≠ se realiza la **extracci√≥n de caracter√≠sticas relevantes** a partir de las im√°genes procesadas y normalizadas en la fase anterior. Estas caracter√≠sticas ser√°n usadas como entrada para los modelos de clasificaci√≥n binaria.  \n",
    "Se implementan t√©cnicas cl√°sicas de procesamiento de im√°genes para capturar informaci√≥n sobre la textura, bordes y patrones presentes en las im√°genes.  \n",
    "\n",
    "---\n",
    "\n",
    "## üéØ Objetivos\n",
    "‚úÖ Leer las im√°genes procesadas desde la carpeta `experiments_png/`.  \n",
    "‚úÖ Extraer descriptores de caracter√≠sticas como:  \n",
    "- Gray Level Co-occurrence Matrix (GLCM).  \n",
    "- Histogram of Oriented Gradients (HOG).  \n",
    "- Local Binary Patterns (LBP).  \n",
    "- Color spaces (LAB).  \n",
    "‚úÖ Explorar otras posibles t√©cnicas como SIFT o SURF (*si el dominio de la imagen lo permite*).  \n",
    "‚úÖ Guardar las caracter√≠sticas extra√≠das en un formato tabular para su uso en la fase de entrenamiento.\n",
    "\n",
    "---\n",
    "\n",
    "## üì¶ üì§ Outputs de la Fase\n",
    "Al finalizar esta fase se generan los siguientes elementos:\n",
    "\n",
    "üìÑ **`features_extracted.csv`**  \n",
    "Archivo CSV que contiene el conjunto de caracter√≠sticas extra√≠das para cada imagen. Incluye:  \n",
    "- Identificador de la imagen.  \n",
    "- Vector de caracter√≠sticas (GLCM, LBP, etc.).  \n",
    "- Clase objetivo (manipulada / no manipulada).  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "07a8d86a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import cv2\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from skimage.feature import local_binary_pattern\n",
    "from skimage.feature import graycomatrix, graycoprops\n",
    "from skimage.color import rgb2gray\n",
    "from tqdm import tqdm  # Barra de progreso\n",
    "import torch\n",
    "import torchvision.models as models\n",
    "import torchvision.transforms as transforms\n",
    "from torchvision.models import ResNet18_Weights\n",
    "from PIL import Image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "b59e47c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extraer_features_glcm(img):\n",
    "    # Configuraci√≥n de GLCM\n",
    "    distances = [1]\n",
    "    angles = [0, np.pi/4, np.pi/2, 3*np.pi/4]\n",
    "\n",
    "    # ------ GLCM Features ------ #\n",
    "    glcm = graycomatrix(img, \n",
    "                        distances=distances, \n",
    "                        angles=angles, \n",
    "                        levels=256, \n",
    "                        symmetric=True, \n",
    "                        normed=True)\n",
    "    \n",
    "    contraste = graycoprops(glcm, 'contrast').flatten()\n",
    "    homogeneidad = graycoprops(glcm, 'homogeneity').flatten()\n",
    "    energia = graycoprops(glcm, 'energy').flatten()\n",
    "    correlacion = graycoprops(glcm, 'correlation').flatten()\n",
    "    entropia = -np.sum(glcm * np.log2(glcm + 1e-10), axis=(0, 1)).flatten()\n",
    "\n",
    "    return np.concatenate([contraste, homogeneidad, energia, correlacion, entropia])\n",
    "\n",
    "def extraer_features_lbp(img):\n",
    "     # Configuraci√≥n de LBP\n",
    "    radius = 1\n",
    "    n_points = 8 * radius\n",
    "    method = 'uniform'  # Da un histograma de 59 bins con 8 vecinos\n",
    "\n",
    "    lbp = local_binary_pattern(img, n_points, radius, method)\n",
    "    hist, _ = np.histogram(lbp.ravel(), \n",
    "                           bins=np.arange(0, n_points + 3),\n",
    "                           range=(0, n_points + 2))\n",
    "    hist = hist.astype(\"float\")\n",
    "    hist /= (hist.sum() + 1e-6)  # Normalizaci√≥n\n",
    "\n",
    "    features_lbp = hist\n",
    "\n",
    "def extraer_features_hog(img):\n",
    "\n",
    "    win_size = (128, 128)\n",
    "    block_size = (32, 32)\n",
    "    block_stride = (16, 16)\n",
    "    cell_size = (8, 8)\n",
    "    nbins = 9\n",
    "\n",
    "    image = cv2.resize(img, win_size)\n",
    "\n",
    "    hog = cv2.HOGDescriptor( win_size,\n",
    "                             block_size,\n",
    "                             block_stride,\n",
    "                             cell_size,\n",
    "                             nbins)\n",
    "    features_hog = hog.compute(img).flatten()\n",
    "    return features_hog"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "d31f1e92",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ResNet preentrenada\n",
    " \n",
    "resnet = models.resnet18(weights=ResNet18_Weights.IMAGENET1K_V1)# Puedes usar resnet34, resnet50, etc.\n",
    "resnet.eval()  # Modo evaluaci√≥n\n",
    "\n",
    "# Quitar la capa final (clasificaci√≥n) para quedarte solo con los features\n",
    "feature_extractor = torch.nn.Sequential(*list(resnet.children())[:-1])\n",
    "\n",
    "# Transformaciones necesarias para la imagen\n",
    "transform = transforms.Compose([\n",
    "    transforms.Resize((224, 224)),  # Las redes esperan 224x224\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=[0.485, 0.456, 0.406],  # ImagenNet stats\n",
    "                         std=[0.229, 0.224, 0.225])\n",
    "])\n",
    "\n",
    "# ---------------- Funci√≥n para extraer features ---------------- #\n",
    "\n",
    "def extraer_features_resnet(img):\n",
    "    img = Image.fromarray(img).convert('RGB')\n",
    "    img = transform(img).unsqueeze(0)  # A√±adir batch dimension\n",
    "    with torch.no_grad():\n",
    "        features = feature_extractor(img).squeeze().numpy()  # shape: (512,)\n",
    "    return features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "f9c15e52",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 492/492 [00:10<00:00, 47.26it/s]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "# ---------------- Configuraci√≥n ---------------- #\n",
    "carpeta_png = 'Experiments-png/'  # Carpeta donde est√°n los PNGs\n",
    "labels = pd.read_csv('labels_final.csv')  # Tu dataframe con columnas uuid, slice, label\n",
    "\n",
    "# Lista para guardar resultados\n",
    "lista_features = []\n",
    "\n",
    "# ---------------- Recorrido ---------------- #\n",
    "for idx, row in tqdm(labels.iterrows(), total=labels.shape[0]):\n",
    "    uuid = row['uuid']\n",
    "    slice_num = row['slice']\n",
    "    etiqueta = row['label']\n",
    "\n",
    "    ruta_imagen = os.path.join(carpeta_png, f\"{uuid}/{slice_num}.png\")\n",
    "    \n",
    "    if not os.path.exists(ruta_imagen):\n",
    "        print(f\"Advertencia: No se encontr√≥ {ruta_imagen}\")\n",
    "        continue\n",
    "\n",
    "    img = cv2.imread(ruta_imagen, cv2.IMREAD_GRAYSCALE)\n",
    "    if img is None:\n",
    "        print(f\"Error cargando {ruta_imagen}\")\n",
    "        continue\n",
    "    \n",
    "    # Extraer features\n",
    "    features_concatenados = []\n",
    "    columnas = []\n",
    "\n",
    "    features_resnet = extraer_features_resnet(img)\n",
    "    features_concatenados = np.concatenate([features_concatenados, features_resnet])\n",
    "    columnas = np.concatenate([columnas,[f'resnet_feat_{i}' for i in range(features_resnet.shape[0])]])\n",
    "    '''\n",
    "    features_lbp = extraer_features_lbp(img)\n",
    "    features_concatenados = np.concatenate([features_concatenados, features_lbp])\n",
    "    columnas = np.concatenate([columnas,[f'lbp_hist_{i}' for i in range(features_lbp.shape[0])]])\n",
    "\n",
    "    features_hog = extraer_features_hog(img)\n",
    "    features_concatenados = np.concatenate([features_concatenados, features_hog])\n",
    "    columnas = np.concatenate([columnas,[f'hog_feat_{i}' for i in range(features_hog.shape[0])]])\n",
    "\n",
    "    features_glcm = extraer_features_glcm(img)\n",
    "    features_glcm = features_glcm.flatten()  # Asegurarse de que es un vector 1D\n",
    "    columnas = np.concatenate([columnas,[f'glcm_feat_{i}' for i in range(features_glcm.shape[0])]])\n",
    "    '''\n",
    "\n",
    "    # Guardar en lista con uuid, slice y label\n",
    "    lista_features.append([uuid, slice_num, etiqueta] + features_concatenados.tolist())\n",
    "\n",
    "# ---------------- DataFrame final ---------------- #\n",
    "\n",
    "# Si tus columnas son un array de nombres, convi√©rtelo a lista plana\n",
    "if isinstance(columnas, np.ndarray):\n",
    "    columnas = columnas.tolist()\n",
    "\n",
    "# Si tus features son: uuid, slice, label, feat1, feat2, ..., featN\n",
    "# Aseg√∫rate de que columnas es una lista plana de nombres de columnas de features\n",
    "columnas_finales = ['uuid', 'slice', 'label'] + columnas\n",
    "df_features = pd.DataFrame(lista_features, columns=columnas_finales)\n",
    "\n",
    "# Eliminar columna slice si no la necesitas\n",
    "df_features = df_features.drop(columns=['slice'])\n",
    "\n",
    "# Reordenar columnas para poner uuid y label al final si as√≠ lo deseas\n",
    "columnas_ordenadas = [col for col in df_features.columns if col not in ['uuid', 'label']] + ['uuid', 'label']\n",
    "df_features = df_features[columnas_ordenadas]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a375efb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Shape final X: (492, 512)\n",
      "‚úÖ Shape final y: (492,)\n",
      "‚úÖ Shape final groups: (492,)\n",
      "‚úÖ Archivo 'features_labels_resnet.npz' guardado exitosamente.\n"
     ]
    }
   ],
   "source": [
    "X = np.array(df_features.drop(columns=['uuid', 'label']))\n",
    "y = np.array(df_features['label'])\n",
    "groups = np.array(df_features['uuid'])\n",
    "\n",
    "print(f\"‚úÖ Shape final X: {X.shape}\")\n",
    "print(f\"‚úÖ Shape final y: {y.shape}\")\n",
    "print(f\"‚úÖ Shape final groups: {groups.shape}\")\n",
    "\n",
    "np.savez_compressed(\"data.npz\", X=X, y=y, groups=groups)\n",
    "print(\"‚úÖ Archivo 'data.npz' guardado exitosamente.\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
