{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "dce84441",
   "metadata": {},
   "source": [
    "# ü©∫ Preparaci√≥n de Datos\n",
    "\n",
    "Este notebook corresponde a la **primera fase del pipeline** para la detecci√≥n de im√°genes m√©dicas manipuladas. Aqu√≠ se realiza la **validaci√≥n de la data original**, la **generaci√≥n de nuevas muestras mediante t√©cnicas de aumento de datos (data augmentation)**, y la conversi√≥n de las im√°genes a un formato legible y est√°ndar (PNG/JPG) para facilitar su uso en etapas posteriores.\n",
    "\n",
    "---\n",
    "\n",
    "## üéØ Objetivos\n",
    "‚úÖ Validar la integridad de la base de datos original (archivos presentes, legibles y correctamente etiquetados).  \n",
    "‚úÖ Generar nuevas muestras para ampliar el conjunto de datos y evitar sobreajuste.  \n",
    "‚úÖ Convertir im√°genes DICOM a un formato est√°ndar y normalizar sus valores de p√≠xel.  \n",
    "‚úÖ Preparar el dataset para las fases de extracci√≥n de caracter√≠sticas y entrenamiento.\n",
    "\n",
    "---\n",
    "\n",
    "## üì¶ üì§ Outputs de la Fase\n",
    "Al finalizar esta fase se generan los siguientes elementos:\n",
    "\n",
    "üìÅ **`Experiments_png/`**  \n",
    "Carpeta que contiene todas las im√°genes procesadas y convertidas a formato `.png`, listas para ser utilizadas en las fases siguientes.\n",
    "\n",
    "üìÑ **`dataset_prepared.csv`**  \n",
    "Archivo CSV que contiene los metadatos del dataset procesado."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "f0c481ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "import glob\n",
    "import random\n",
    "import cv2\n",
    "import numpy as np\n",
    "import pydicom"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "651d1749",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def create_labels_TB(df, n, seed=None):\n",
    "\n",
    "    for idx, row in df.loc[df['type'] == 'TB'].iterrows():\n",
    "        folder = os.path.join('Experiments', str(row.uuid))\n",
    "        files = glob.glob(os.path.join(folder, '*.dcm'))\n",
    "        id = list(map(lambda x: int(os.path.basename(x).split('.')[0]), files))\n",
    "        if seed is not None:\n",
    "            random.seed(seed)\n",
    "        df.loc[idx, 'slice'] = random.randint(n, max(id)-n)\n",
    "\n",
    "def add_labels(df, n=1, st=1):\n",
    "\n",
    "    temp = df.copy()\n",
    "    temp['generated'] = 0\n",
    "    for i in range(n):\n",
    "        temp1 = df.copy()\n",
    "        temp2 = df.copy()\n",
    "        temp1['slice'] = temp1['slice']-(1+i*st)\n",
    "        temp1['generated'] = 1\n",
    "        temp2['slice'] = temp2['slice']+(1+i*st)\n",
    "        temp2['generated'] = 1\n",
    "        temp = pd.concat([temp, temp1, temp2], ignore_index=True)\n",
    "    return temp\n",
    "\n",
    "def transfor_image(img, seed=None):\n",
    "\n",
    "    np.random.seed(seed)\n",
    "    dgreges = np.random.randint(-7, 7)\n",
    "    scale = np.random.uniform(0.9, 1.0)\n",
    "    center = (img.shape[1] // 2, img.shape[0] // 2)\n",
    "    M = cv2.getRotationMatrix2D(center, dgreges, scale)\n",
    "    img = cv2.warpAffine(img, M, (img.shape[1], img.shape[0]), flags=cv2.INTER_LINEAR)\n",
    "\n",
    "    std = img.std()\n",
    "    gauss = np.random.normal(0, std/100, img.shape).astype(np.float32)\n",
    "    beta = np.random.randint(-10, 10, img.shape).astype(np.float32)\n",
    "    \n",
    "    img = img + gauss\n",
    "    img = img + beta\n",
    "    \n",
    "    img = np.clip(img, 0, 255).astype(np.uint8)\n",
    "    return img\n",
    "\n",
    "def dcm_a_png(dcm_path, png_path, window_min=-1000, window_max=400, transform=False, seed=None):\n",
    "\n",
    "    try:\n",
    "        ds = pydicom.dcmread(dcm_path)\n",
    "        img = ds.pixel_array.astype(np.float32)\n",
    "        img = np.clip(img, window_min, window_max)\n",
    "        img = ((img - window_min) / (window_max - window_min)) * 255.0\n",
    "        img = img.astype(np.uint8)\n",
    "        os.makedirs(os.path.dirname(png_path), exist_ok=True)\n",
    "        if transform:\n",
    "            img = transfor_image(img, seed=42)\n",
    "        cv2.imwrite(png_path, img)\n",
    "    except Exception as e:\n",
    "        print(f\"Error procesando {dcm_path}: {e}\")\n",
    "\n",
    "def convertir_df_dcm_a_png(df, input_dir='Experiments', output_dir='output_png',\n",
    "                           window_min=-1000, window_max=400):\n",
    "\n",
    "    for idx, row in df.iterrows():\n",
    "        uuid = row['uuid']\n",
    "        slice_num = row['slice']\n",
    "        transform = True if row['generated'] == 1 else False\n",
    "        dcm_file = os.path.join(input_dir, f\"{uuid}/{slice_num}.dcm\")\n",
    "        png_file = os.path.join(output_dir, f\"{uuid}/{slice_num}.png\")\n",
    "        if os.path.exists(dcm_file):\n",
    "            dcm_a_png(dcm_file, png_file, window_min, window_max, transform=transform, seed=42)\n",
    "        else:\n",
    "            print(f\"No encontrado: {dcm_file}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30e994ca",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tama√±o original: (158, 6)\n",
      "Tama√±o final: (474, 7)\n",
      "label\n",
      "1    339\n",
      "0    135\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "labels = pd.read_csv('labels.csv', sep=';') # Cargar dataset original\n",
    "\n",
    "labels['label'] = labels['type'].apply(lambda x: 1 if x.startswith('F') else (0 if x.startswith('T') else '')) # Etiquetar las clases: 1 para 'F', 0 para 'T'\n",
    "\n",
    "# Filtrar NO-TB y TB por separado\n",
    "no_tb = labels[labels['type'] != 'TB']\n",
    "tb = labels[labels['type'] == 'TB'].drop_duplicates(subset='uuid')\n",
    "\n",
    "# Concatenar todo de nuevo\n",
    "labels = pd.concat([no_tb, tb], ignore_index=True)\n",
    "\n",
    "print(\"Tama√±o original:\", labels.shape)\n",
    "\n",
    "n = 1 # Elegir n para crear slices v√°lidos en TB\n",
    "create_labels_TB(labels, n, seed=42) # Asignar slices v√°lidos a TB\n",
    "labels = add_labels(labels, n, st=5) # Expandir todos los datos con n vecinos con un paso de st\n",
    "#labels = expandir_tb_con_vecinos(labels, n_vecinos=1) # Balancear agregando m√°s vecinos a TB (no duplica arbitrariamente)\n",
    "\n",
    "print(\"Tama√±o final:\", labels.shape)\n",
    "print(labels['label'].value_counts())\n",
    "\n",
    "labels.to_csv('labels_final.csv', index=False) # Guardar el DataFrame con las etiquetas y slices generados\n",
    "\n",
    "convertir_df_dcm_a_png(labels, input_dir='Experiments', output_dir='Experiments-png') # Convertir DICOM a PNG"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
