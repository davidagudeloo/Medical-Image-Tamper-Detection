{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "dce84441",
   "metadata": {},
   "source": [
    "# ü©∫ 01_Data_Preparation / Preparaci√≥n de Datos\n",
    "\n",
    "## üìù Descripci√≥n\n",
    "Este notebook corresponde a la **primera fase del pipeline** para la detecci√≥n de im√°genes m√©dicas manipuladas. Aqu√≠ se realiza la **validaci√≥n de la data original**, la **generaci√≥n de nuevas muestras mediante t√©cnicas de aumento de datos (data augmentation)**, y la conversi√≥n de las im√°genes a un formato legible y est√°ndar (PNG/JPG) para facilitar su uso en etapas posteriores.\n",
    "\n",
    "---\n",
    "\n",
    "## üéØ Objetivos\n",
    "‚úÖ Validar la integridad de la base de datos original (archivos presentes, legibles y correctamente etiquetados).  \n",
    "‚úÖ Generar nuevas muestras para ampliar el conjunto de datos y evitar sobreajuste.  \n",
    "‚úÖ Convertir im√°genes DICOM a un formato est√°ndar y normalizar sus valores de p√≠xel.  \n",
    "‚úÖ Preparar el dataset para las fases de extracci√≥n de caracter√≠sticas y entrenamiento.\n",
    "\n",
    "---\n",
    "\n",
    "## üìù Description\n",
    "This notebook corresponds to the **first stage of the pipeline** for detecting tampered medical images. Here we perform **validation of the original dataset**, **generation of new samples through data augmentation techniques**, and **conversion of images into a readable and standard format (PNG/JPG)** to facilitate usage in subsequent stages.\n",
    "\n",
    "---\n",
    "\n",
    "## üéØ Objectives\n",
    "‚úÖ Validate the integrity of the original dataset (check for missing, unreadable, or mislabelled files).  \n",
    "‚úÖ Generate new samples to expand the dataset and prevent overfitting.  \n",
    "‚úÖ Convert DICOM images into a standard format and normalize pixel values.  \n",
    "‚úÖ Prepare the dataset for the feature extraction and training stages."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f0c481ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "import glob\n",
    "import random\n",
    "import cv2\n",
    "import numpy as np\n",
    "import pydicom"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "651d1749",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def create_labels_TB(df, n, seed=None):\n",
    "    '''\n",
    "    Create labels for the TB dataset by randomly selecting slices from the existing images.\n",
    "    '''\n",
    "    for idx, row in df.loc[df['type'] == 'TB'].iterrows():\n",
    "        folder = os.path.join('Experiments', str(row.uuid))\n",
    "        files = glob.glob(os.path.join(folder, '*.dcm'))\n",
    "        id = list(map(lambda x: int(os.path.basename(x).split('.')[0]), files))\n",
    "        if seed is not None:\n",
    "            random.seed(seed)\n",
    "        df.loc[idx, 'slice'] = random.randint(n, max(id)-n)\n",
    "\n",
    "def add_labels(df, n=1, st=1):\n",
    "    '''\n",
    "    Add labels to the dataframe by generating new slices based on the existing ones.\n",
    "    '''\n",
    "    temp = df.copy()\n",
    "    temp['generated'] = 0\n",
    "    for i in range(n):\n",
    "        temp1 = df.copy()\n",
    "        temp2 = df.copy()\n",
    "        temp1['slice'] = temp1['slice']-(1+i*st)\n",
    "        temp1['generated'] = 1\n",
    "        temp2['slice'] = temp2['slice']+(1+i*st)\n",
    "        temp2['generated'] = 1\n",
    "        temp = pd.concat([temp, temp1, temp2], ignore_index=True)\n",
    "    return temp\n",
    "\n",
    "def transfor_image(img, seed=None):\n",
    "    '''\n",
    "    Apply random transformations to the image.\n",
    "    '''\n",
    "    np.random.seed(seed)\n",
    "    dgreges = np.random.randint(-7, 7)\n",
    "    scale = np.random.uniform(0.9, 1.0)\n",
    "    center = (img.shape[1] // 2, img.shape[0] // 2)\n",
    "    M = cv2.getRotationMatrix2D(center, dgreges, scale)\n",
    "    img = cv2.warpAffine(img, M, (img.shape[1], img.shape[0]), flags=cv2.INTER_LINEAR)\n",
    "\n",
    "    std = img.std()\n",
    "    gauss = np.random.normal(0, std/100, img.shape).astype(np.float32)\n",
    "    beta = np.random.randint(-10, 10, img.shape).astype(np.float32)\n",
    "    \n",
    "    img = img + gauss\n",
    "    img = img + beta\n",
    "    \n",
    "    img = np.clip(img, 0, 255).astype(np.uint8)\n",
    "    return img\n",
    "\n",
    "def dcm_a_png(dcm_path, png_path, window_min=-1000, window_max=400, transform=False, seed=None):\n",
    "    '''\n",
    "    Convert a DICOM file to PNG format with optional transformations.\n",
    "    '''\n",
    "    try:\n",
    "        ds = pydicom.dcmread(dcm_path)\n",
    "        img = ds.pixel_array.astype(np.float32)\n",
    "        img = np.clip(img, window_min, window_max)\n",
    "        img = ((img - window_min) / (window_max - window_min)) * 255.0\n",
    "        img = img.astype(np.uint8)\n",
    "        os.makedirs(os.path.dirname(png_path), exist_ok=True)\n",
    "        if transform:\n",
    "            img = transfor_image(img, seed=42)  # Aplicar transformaci√≥n\n",
    "        cv2.imwrite(png_path, img)\n",
    "    except Exception as e:\n",
    "        print(f\"Error procesando {dcm_path}: {e}\")\n",
    "\n",
    "def convertir_df_dcm_a_png(df, input_dir='Experiments', output_dir='output_png',\n",
    "                           window_min=-1000, window_max=400):\n",
    "    '''\n",
    "    Convert a DataFrame of DICOM files to PNG format with optional transformations.\n",
    "    '''\n",
    "    for idx, row in df.iterrows():\n",
    "        uuid = row['uuid']\n",
    "        slice_num = row['slice']\n",
    "        transform = True if row['generated'] == 1 else False\n",
    "        dcm_file = os.path.join(input_dir, f\"{uuid}/{slice_num}.dcm\")\n",
    "        png_file = os.path.join(output_dir, f\"{uuid}/{slice_num}.png\")\n",
    "        if os.path.exists(dcm_file):\n",
    "            dcm_a_png(dcm_file, png_file, window_min, window_max, transform=transform, seed=42)\n",
    "        else:\n",
    "            print(f\"No encontrado: {dcm_file}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30e994ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "labels = pd.read_csv('labels.csv', sep=';') # Cargar dataset original\n",
    "\n",
    "labels['tag'] = labels['type'].apply(lambda x: 1 if x.startswith('F') else (0 if x.startswith('T') else '')) # Etiquetar las clases: 1 para 'F', 0 para 'T'\n",
    "\n",
    "print(\"Tama√±o original:\", labels.shape)\n",
    "n = 1 # Elegir n para crear slices v√°lidos en TB\n",
    "create_labels_TB(labels, n, seed=42) # Asignar slices v√°lidos a TB\n",
    "labels = add_labels(labels, n, st=2) # Expandir todos los datos con n vecinos con un paso de st\n",
    "#labels = expandir_tb_con_vecinos(labels, n_vecinos=1) # Balancear agregando m√°s vecinos a TB (no duplica arbitrariamente)\n",
    "\n",
    "print(\"Tama√±o final:\", labels.shape)\n",
    "print(labels['tag'].value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c717f642",
   "metadata": {},
   "outputs": [],
   "source": [
    "labels.to_csv('labels_temp.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d700de01",
   "metadata": {},
   "outputs": [],
   "source": [
    "convertir_df_dcm_a_png(labels, input_dir='Experiments', output_dir='Experiments-png')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.13.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
