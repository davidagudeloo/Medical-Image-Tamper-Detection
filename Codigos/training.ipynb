{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 150,
   "id": "6fd4f2d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "# Cargar el archivo\n",
    "data = np.load(\"df-deepfake-lbp.npz\")\n",
    "\n",
    "# Acceder a los arrays\n",
    "X = data['X']\n",
    "y = data['y']\n",
    "uuids = data['uuids']\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "74e861ea",
   "metadata": {},
   "source": [
    "Forma1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "id": "6570d3cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import GroupShuffleSplit\n",
    "\n",
    "# 1. Dividir train (70%) y temporal (30%)\n",
    "splitter_temp = GroupShuffleSplit(test_size=0.4, n_splits=1, random_state=42)\n",
    "train_idx, temp_idx = next(splitter_temp.split(X, groups=uuids))\n",
    "\n",
    "# 2. Dividir temporal en val (15%) y test (15%)\n",
    "splitter_final = GroupShuffleSplit(test_size=0.5, n_splits=1, random_state=42)\n",
    "val_idx, test_idx = next(splitter_final.split(X[temp_idx], groups=uuids[temp_idx]))\n",
    "val_idx = temp_idx[val_idx]  # Ajustar índices al array original\n",
    "test_idx = temp_idx[test_idx]\n",
    "\n",
    "# 3. Crear conjuntos FINALES (X e y se filtran con los mismos índices)\n",
    "X_train, y_train = X[train_idx], y[train_idx]  # <-- X y y de train\n",
    "X_val, y_val = X[val_idx], y[val_idx]          # <-- X y y de val\n",
    "X_test, y_test = X[test_idx], y[test_idx]      # <-- X y y de test\n",
    "\n",
    "\n",
    "# Guardar todos los conjuntos en un único archivo\n",
    "np.savez_compressed(\n",
    "    \"deepfake_dataset_splits.npz\",  \n",
    "    X_train=X_train, y_train=y_train,  # Train\n",
    "    X_val=X_val, y_val=y_val,          # Validation\n",
    "    X_test=X_test, y_test=y_test,      # Test\n",
    "    uuids_train=uuids[train_idx],      # UUIDs de train (opcional)\n",
    "    uuids_val=uuids[val_idx],          # UUIDs de val (opcional)\n",
    "    uuids_test=uuids[test_idx]         # UUIDs de test (opcional)\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "02266b6b",
   "metadata": {},
   "source": [
    "Forma 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "id": "f8cbe36a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Agrupar por paciente\n",
    "df = pd.DataFrame({'uuid': uuids, 'label': y})\n",
    "\n",
    "# Asegúrate que cada paciente tiene una sola clase (revisar antes)\n",
    "df_group = df.groupby('uuid').agg({'label': 'first'}).reset_index()\n",
    "\n",
    "# Split estratificado por paciente\n",
    "train_uuids, temp_uuids = train_test_split(\n",
    "    df_group['uuid'], \n",
    "    test_size=0.4, \n",
    "    stratify=df_group['label'], \n",
    "    random_state=42\n",
    ")\n",
    "\n",
    "val_uuids, test_uuids = train_test_split(\n",
    "    temp_uuids, \n",
    "    test_size=0.5, \n",
    "    stratify=df_group.set_index('uuid').loc[temp_uuids]['label'], \n",
    "    random_state=42\n",
    ")\n",
    "\n",
    "# Crear índices finales\n",
    "train_idx = df[df['uuid'].isin(train_uuids)].index\n",
    "val_idx = df[df['uuid'].isin(val_uuids)].index\n",
    "test_idx = df[df['uuid'].isin(test_uuids)].index\n",
    "\n",
    "# 3. Crear conjuntos FINALES (X e y se filtran con los mismos índices)\n",
    "X_train, y_train = X[train_idx], y[train_idx]  # <-- X y y de train\n",
    "X_val, y_val = X[val_idx], y[val_idx]          # <-- X y y de val\n",
    "X_test, y_test = X[test_idx], y[test_idx]      # <-- X y y de test\n",
    "\n",
    "# Guardar todos los conjuntos en un único archivo\n",
    "np.savez_compressed(\n",
    "    \"deepfake_dataset_splits.npz\",  \n",
    "    X_train=X_train, y_train=y_train,  # Train\n",
    "    X_val=X_val, y_val=y_val,          # Validation\n",
    "    X_test=X_test, y_test=y_test,      # Test\n",
    "    uuids_train=uuids[train_idx],      # UUIDs de train (opcional)\n",
    "    uuids_val=uuids[val_idx],          # UUIDs de val (opcional)\n",
    "    uuids_test=uuids[test_idx]         # UUIDs de test (opcional)\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "id": "67f3cbaa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Conteo de clases en y_train:\n",
      "Clase 0: 930 muestras\n",
      "Clase 1: 1050 muestras\n",
      "Conteo de clases en y_val:\n",
      "Clase 0: 90 muestras\n",
      "Clase 1: 360 muestras\n",
      "Conteo de clases en y_test:\n",
      "Clase 0: 375 muestras\n",
      "Clase 1: 285 muestras\n"
     ]
    }
   ],
   "source": [
    "# Conteo de clases\n",
    "unique, counts = np.unique(y_train, return_counts=True)\n",
    "print(\"Conteo de clases en y_train:\")\n",
    "for cls, cnt in zip(unique, counts):\n",
    "    print(f\"Clase {cls}: {cnt} muestras\")\n",
    "\n",
    "# Conteo de clases\n",
    "unique, counts = np.unique(y_val, return_counts=True)\n",
    "print(\"Conteo de clases en y_val:\")\n",
    "for cls, cnt in zip(unique, counts):\n",
    "    print(f\"Clase {cls}: {cnt} muestras\")\n",
    "\n",
    "# Conteo de clases\n",
    "unique, counts = np.unique(y_test, return_counts=True)\n",
    "print(\"Conteo de clases en y_test:\")\n",
    "for cls, cnt in zip(unique, counts):\n",
    "    print(f\"Clase {cls}: {cnt} muestras\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7e7df673",
   "metadata": {},
   "source": [
    "Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "id": "f725c516",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🔍 Mejor combinación de hiperparámetros: {'C': 0.01, 'penalty': 'l2', 'solver': 'lbfgs'}\n",
      "📈 Mejor F1-score (CV): 0.6968\n",
      "✅ Accuracy medio: 0.6707\n",
      "✅ Recall medio:   0.7221\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.utils.class_weight import compute_class_weight\n",
    "import numpy as np\n",
    "\n",
    "# Cargar datos\n",
    "data = np.load(\"deepfake_dataset_splits.npz\")\n",
    "X_train = data['X_train']\n",
    "y_train = data['y_train']\n",
    "\n",
    "\n",
    "# Escalar manualmente\n",
    "scaler = StandardScaler()\n",
    "X_scaled = scaler.fit_transform(X_train)\n",
    "\n",
    "\n",
    "\n",
    "# Modelo base\n",
    "lr = LogisticRegression(max_iter=1000)\n",
    "\n",
    "# Definir grilla de hiperparámetros\n",
    "param_grid = {\n",
    "    'C': [0.01, 0.1, 1, 10, 100],             # Regularización\n",
    "    'solver': ['lbfgs', 'liblinear'],         # Algoritmos\n",
    "    'penalty': ['l2']                         # Tipo de penalización (solo 'l2' es compatible con lbfgs y liblinear)\n",
    "}\n",
    "\n",
    "# Métricas para evaluar\n",
    "scoring = {\n",
    "    'accuracy': 'accuracy',\n",
    "    'recall': 'recall',\n",
    "    'f1': 'f1'\n",
    "}\n",
    "\n",
    "# Grid Search con CV\n",
    "grid = GridSearchCV(estimator=lr, param_grid=param_grid, cv=5,\n",
    "                    scoring=scoring, refit='f1', return_train_score=False)\n",
    "\n",
    "# Entrenar\n",
    "grid.fit(X_scaled, y_train)\n",
    "\n",
    "# Resultados\n",
    "print(\"🔍 Mejor combinación de hiperparámetros:\", grid.best_params_)\n",
    "print(f\"📈 Mejor F1-score (CV): {grid.best_score_:.4f}\")\n",
    "\n",
    "# Puedes imprimir más métricas si deseas:\n",
    "means = grid.cv_results_\n",
    "print(f\"✅ Accuracy medio: {means['mean_test_accuracy'][grid.best_index_]:.4f}\")\n",
    "print(f\"✅ Recall medio:   {means['mean_test_recall'][grid.best_index_]:.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "id": "31c58bcd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🔹 Evaluación en TRAIN:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        Real       0.64      0.66      0.65      1050\n",
      "        Fake       0.69      0.67      0.68      1155\n",
      "\n",
      "    accuracy                           0.67      2205\n",
      "   macro avg       0.66      0.67      0.66      2205\n",
      "weighted avg       0.67      0.67      0.67      2205\n",
      "\n",
      "\n",
      "🔹 Evaluación en VALIDACIÓN:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        Real       0.44      0.41      0.42       195\n",
      "        Fake       0.48      0.52      0.50       210\n",
      "\n",
      "    accuracy                           0.46       405\n",
      "   macro avg       0.46      0.46      0.46       405\n",
      "weighted avg       0.46      0.46      0.46       405\n",
      "\n",
      "\n",
      "Features seleccionadas: 20\n",
      "Coeficientes más importantes:\n",
      "[(139.05435974602517, 21), (130.49433608672894, 22), (102.08122624373964, 0), (92.32378340736473, 8), (89.58763183719284, 1), (65.41937912033795, 24), (57.68408421198129, 25), (54.803321835091715, 19), (49.16077774487696, 20), (46.996762990010055, 9)]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.feature_selection import SelectKBest, f_classif\n",
    "import numpy as np\n",
    "\n",
    "# 1. Cargar datos\n",
    "data = np.load(\"deepfake_dataset_splits.npz\")\n",
    "X_train = data['X_train']\n",
    "y_train = data['y_train']\n",
    "X_val = data['X_val']\n",
    "y_val = data['y_val']\n",
    "\n",
    "# 2. Escalado y selección de características\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_val_scaled = scaler.transform(X_val)\n",
    "\n",
    "# Selección de las 20 mejores características (ajusta este número según necesidad)\n",
    "selector = SelectKBest(f_classif, k=20)\n",
    "X_train_selected = selector.fit_transform(X_train_scaled, y_train)\n",
    "X_val_selected = selector.transform(X_val_scaled)\n",
    "\n",
    "# 3. Balanceo mediante class_weight\n",
    "classes = np.unique(y_train)\n",
    "class_weights = dict(zip(classes, compute_class_weight('balanced', classes=classes, y=y_train)))\n",
    "\n",
    "# 4. Modelo con ajuste fino\n",
    "lr = LogisticRegression(\n",
    "    C=0.1,                   # Mayor regularización\n",
    "    penalty='l2',\n",
    "    solver='liblinear',\n",
    "    class_weight=class_weights,  # Balance automático\n",
    "    max_iter=1000,           # Más iteraciones para convergencia\n",
    "    random_state=42\n",
    ")\n",
    "\n",
    "# 5. Entrenamiento y evaluación\n",
    "lr.fit(X_train_selected, y_train)\n",
    "\n",
    "print(\"🔹 Evaluación en TRAIN:\")\n",
    "print(classification_report(y_train, lr.predict(X_train_selected), target_names=[\"Real\", \"Fake\"]))\n",
    "\n",
    "print(\"\\n🔹 Evaluación en VALIDACIÓN:\")\n",
    "y_pred_val = lr.predict(X_val_selected)\n",
    "print(classification_report(y_val, y_pred_val, target_names=[\"Real\", \"Fake\"]))\n",
    "\n",
    "# 6. Análisis adicional (opcional)\n",
    "print(\"\\nFeatures seleccionadas:\", X_train_selected.shape[1])\n",
    "print(\"Coeficientes más importantes:\")\n",
    "print(sorted(zip(selector.scores_, range(X_train_scaled.shape[1])), reverse=True)[:10])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0faca907",
   "metadata": {},
   "source": [
    "Knn Neighbors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "id": "d3031f82",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 6 candidates, totalling 30 fits\n",
      "🔍 Mejor combinación de hiperparámetros: {'metric': 'manhattan', 'n_neighbors': 15, 'weights': 'uniform'}\n",
      "📈 Mejor F1-score (CV): 0.9509\n",
      "✅ Accuracy medio:       0.9451\n",
      "✅ Recall medio:         0.9354\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import numpy as np\n",
    "\n",
    "# Cargar datos\n",
    "data = np.load(\"deepfake_dataset_splits.npz\")\n",
    "X_train = data['X_train']\n",
    "y_train = data['y_train']\n",
    "\n",
    "# Calcular pesos para TRAIN (usando y_train)\n",
    "classes = np.unique(y_train)\n",
    "weights = compute_class_weight(class_weight='balanced', classes=classes, y=y_train)\n",
    "class_weights = {0: weights[0], 1: weights[1]}\n",
    "\n",
    "# Escalar\n",
    "scaler = StandardScaler()\n",
    "X_scaled = scaler.fit_transform(X_train)\n",
    "\n",
    "# Modelo base\n",
    "knn = KNeighborsClassifier()\n",
    "\n",
    "# Grilla de hiperparámetros\n",
    "param_grid = {\n",
    "    'n_neighbors': [ 15, 25, 35],\n",
    "    'weights': ['uniform'],\n",
    "    'metric': ['euclidean', 'manhattan']\n",
    "}\n",
    "\n",
    "# Scoring múltiple\n",
    "scoring = {\n",
    "    'accuracy': 'accuracy',\n",
    "    'recall': 'recall',\n",
    "    'f1': 'f1'\n",
    "}\n",
    "\n",
    "# GridSearch con múltiples métricas\n",
    "grid = GridSearchCV(\n",
    "    estimator=knn,\n",
    "    param_grid=param_grid,\n",
    "    scoring=scoring,\n",
    "    refit='f1',  # el mejor se elige por f1\n",
    "    cv=5,\n",
    "    n_jobs=-1,\n",
    "    verbose=1\n",
    ")\n",
    "\n",
    "# Entrenar\n",
    "grid.fit(X_scaled, y_train)\n",
    "\n",
    "# Resultados\n",
    "print(\"🔍 Mejor combinación de hiperparámetros:\", grid.best_params_)\n",
    "print(f\"📈 Mejor F1-score (CV): {grid.cv_results_['mean_test_f1'][grid.best_index_]:.4f}\")\n",
    "print(f\"✅ Accuracy medio:       {grid.cv_results_['mean_test_accuracy'][grid.best_index_]:.4f}\")\n",
    "print(f\"✅ Recall medio:         {grid.cv_results_['mean_test_recall'][grid.best_index_]:.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "id": "fa2830fb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🔹 Evaluación en TRAIN:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.86      0.84      0.85       735\n",
      "           1       0.88      0.89      0.88       960\n",
      "\n",
      "    accuracy                           0.87      1695\n",
      "   macro avg       0.87      0.86      0.87      1695\n",
      "weighted avg       0.87      0.87      0.87      1695\n",
      "\n",
      "\n",
      "🔹 Evaluación en VALIDACIÓN:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.46      0.42      0.44       240\n",
      "           1       0.65      0.69      0.67       375\n",
      "\n",
      "    accuracy                           0.58       615\n",
      "   macro avg       0.56      0.55      0.55       615\n",
      "weighted avg       0.58      0.58      0.58       615\n",
      "\n",
      "\n",
      "Se seleccionaron 20 features.\n",
      "Scores de las features seleccionadas: [ 44.16249644  35.76016465  17.39003902  11.5636855   27.52878297\n",
      " 124.22427897 129.80271157 109.49668531  52.57263597   8.25835321\n",
      "   8.15699182   6.08071788  17.85419208  96.01877444 101.8861173\n",
      " 104.80799766  51.89177891   7.05015988   7.47478847  15.44658168]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.feature_selection import VarianceThreshold, SelectKBest, f_classif\n",
    "from sklearn.metrics import classification_report\n",
    "import numpy as np\n",
    "\n",
    "# 1. Cargar datos\n",
    "data = np.load(\"deepfake_dataset_splits.npz\")\n",
    "X_train = data['X_train']\n",
    "y_train = data['y_train']\n",
    "X_val = data['X_val']\n",
    "y_val = data['y_val']\n",
    "\n",
    "# 2. Escalado\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_val_scaled = scaler.transform(X_val)\n",
    "\n",
    "# 3. Selección de features (VarianceThreshold + Top 20)\n",
    "# Primero elimina features con varianza < 0.01\n",
    "var_selector = VarianceThreshold(threshold=0.01)\n",
    "X_train_var = var_selector.fit_transform(X_train_scaled)\n",
    "X_val_var = var_selector.transform(X_val_scaled)\n",
    "\n",
    "# Luego selecciona las 20 mejores con ANOVA F\n",
    "kbest_selector = SelectKBest(f_classif, k=20)\n",
    "X_train_selected = kbest_selector.fit_transform(X_train_var, y_train)\n",
    "X_val_selected = kbest_selector.transform(X_val_var)\n",
    "\n",
    "# 4. Entrenar KNN (configuración original)\n",
    "knn = KNeighborsClassifier(\n",
    "    n_neighbors=50,\n",
    "    weights='uniform',\n",
    "    metric='euclidean'\n",
    ")\n",
    "knn.fit(X_train_selected, y_train)\n",
    "\n",
    "# 5. Evaluación\n",
    "print(\"🔹 Evaluación en TRAIN:\")\n",
    "print(classification_report(y_train, knn.predict(X_train_selected)))\n",
    "\n",
    "print(\"\\n🔹 Evaluación en VALIDACIÓN:\")\n",
    "print(classification_report(y_val, knn.predict(X_val_selected)))\n",
    "\n",
    "# Opcional: Ver features seleccionadas\n",
    "print(f\"\\nSe seleccionaron {X_train_selected.shape[1]} features.\")\n",
    "print(\"Scores de las features seleccionadas:\", kbest_selector.scores_[kbest_selector.get_support()])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9450acfc",
   "metadata": {},
   "source": [
    "Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db0ac7dc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 24 candidates, totalling 120 fits\n",
      "🔍 Mejor combinación de hiperparámetros: {'max_depth': 15, 'min_samples_leaf': 1, 'min_samples_split': 2, 'n_estimators': 200}\n",
      "📈 Mejor F1-score (CV): 0.9622\n",
      "✅ Accuracy medio:       0.9601\n",
      "✅ Recall medio:         0.9662\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import numpy as np\n",
    "\n",
    "# Cargar datos\n",
    "data = np.load(\"deepfake_dataset_splits.npz\")\n",
    "X_train = data['X_train']\n",
    "y_train = data['y_train']\n",
    "\n",
    "\n",
    "# Escalar\n",
    "scaler = StandardScaler()\n",
    "X_scaled = scaler.fit_transform(X_train)\n",
    "\n",
    "# Definir modelo base\n",
    "rf = RandomForestClassifier(random_state=42)\n",
    "\n",
    "# Definir la grilla de hiperparámetros\n",
    "param_grid = {\n",
    "    'n_estimators': [100, 200],\n",
    "    'max_depth': [5, 10, 15],\n",
    "    'min_samples_split': [2, 5],\n",
    "    'min_samples_leaf': [1, 2]\n",
    "}\n",
    "\n",
    "scoring = {\n",
    "    'accuracy': 'accuracy',\n",
    "    'recall': 'recall',\n",
    "    'f1': 'f1'\n",
    "}\n",
    "\n",
    "# Crear GridSearchCV\n",
    "grid = GridSearchCV(\n",
    "    estimator=rf,\n",
    "    param_grid=param_grid,\n",
    "    scoring=scoring,  # también puedes usar 'recall' si priorizas eso\n",
    "    cv=5,\n",
    "    refit='f1',  # el mejor se elige por f1\n",
    "    n_jobs=-1,\n",
    "    verbose=1\n",
    ")\n",
    "\n",
    "# Ejecutar búsqueda\n",
    "grid.fit(X_scaled, y_train)\n",
    "\n",
    "# Resultados\n",
    "print(\"🔍 Mejor combinación de hiperparámetros:\", grid.best_params_)\n",
    "print(f\"📈 Mejor F1-score (CV): {grid.cv_results_['mean_test_f1'][grid.best_index_]:.4f}\")\n",
    "print(f\"✅ Accuracy medio:       {grid.cv_results_['mean_test_accuracy'][grid.best_index_]:.4f}\")\n",
    "print(f\"✅ Recall medio:         {grid.cv_results_['mean_test_recall'][grid.best_index_]:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b9c69e43",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🔹 Evaluación en TRAIN:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.95      0.90      0.92       960\n",
      "           1       0.90      0.95      0.93       960\n",
      "\n",
      "    accuracy                           0.93      1920\n",
      "   macro avg       0.93      0.93      0.93      1920\n",
      "weighted avg       0.93      0.93      0.93      1920\n",
      "\n",
      "🔹 Evaluación en VALIDACIÓN:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.46      0.48      0.47       240\n",
      "           1       0.66      0.64      0.65       375\n",
      "\n",
      "    accuracy                           0.58       615\n",
      "   macro avg       0.56      0.56      0.56       615\n",
      "weighted avg       0.58      0.58      0.58       615\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import classification_report\n",
    "import numpy as np\n",
    "\n",
    "# Cargar datos\n",
    "data = np.load(\"deepfake_dataset_splits.npz\")\n",
    "X_train = data['X_train']\n",
    "y_train = data['y_train']\n",
    "\n",
    "X_val = data['X_val']\n",
    "y_val = data['y_val']\n",
    "\n",
    "\n",
    "# 2. Escalar los datos\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_val_scaled = scaler.transform(X_val)\n",
    "\n",
    "# 3. Crear y entrenar modelo\n",
    "rf = RandomForestClassifier(max_depth= 5, min_samples_leaf= 1, min_samples_split= 2, n_estimators = 100, random_state=42)\n",
    "rf.fit(X_train_scaled, y_train)\n",
    "\n",
    "# 4. Evaluar en entrenamiento y validación\n",
    "print(\"🔹 Evaluación en TRAIN:\")\n",
    "print(classification_report(y_train, rf.predict(X_train_scaled)))\n",
    "\n",
    "print(\"🔹 Evaluación en VALIDACIÓN:\")\n",
    "print(classification_report(y_val, rf.predict(X_val_scaled)))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "22abaf67",
   "metadata": {},
   "source": [
    "SVM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "78f460c2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 54 candidates, totalling 270 fits\n",
      "🔍 Mejor combinación de hiperparámetros: {'C': 10, 'degree': 2, 'gamma': 0.1, 'kernel': 'rbf'}\n",
      "📈 Mejor F1-score (CV): 0.9803\n",
      "✅ Accuracy medio:       0.9785\n",
      "✅ Recall medio:         0.9746\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import numpy as np\n",
    "\n",
    "# Cargar datos\n",
    "data_train = np.load(\"deepfake_trainval.npz\")\n",
    "X = data_train['X']\n",
    "y = data_train['y']\n",
    "\n",
    "# Escalar datos\n",
    "scaler = StandardScaler()\n",
    "X_scaled = scaler.fit_transform(X)\n",
    "\n",
    "# Definir modelo\n",
    "svm = SVC(random_state=42)\n",
    "\n",
    "# Grilla de hiperparámetros\n",
    "param_grid = {\n",
    "        'kernel': ['linear','rbf', 'poly' ],\n",
    "        'C': [0.1, 1, 10],\n",
    "        'degree': [2, 3],\n",
    "        'gamma': ['scale', 0.01, 0.1]\n",
    "    }\n",
    "\n",
    "# Métricas\n",
    "scoring = {\n",
    "    'accuracy': 'accuracy',\n",
    "    'recall': 'recall',\n",
    "    'f1': 'f1'\n",
    "}\n",
    "\n",
    "# GridSearchCV\n",
    "grid = GridSearchCV(\n",
    "    estimator=svm,\n",
    "    param_grid=param_grid,\n",
    "    scoring=scoring,\n",
    "    refit='f1',\n",
    "    cv=5,\n",
    "    n_jobs=-1,\n",
    "    verbose=1\n",
    ")\n",
    "\n",
    "# Ajustar\n",
    "grid.fit(X_scaled, y)\n",
    "\n",
    "# Resultados\n",
    "print(\"🔍 Mejor combinación de hiperparámetros:\", grid.best_params_)\n",
    "print(f\"📈 Mejor F1-score (CV): {grid.cv_results_['mean_test_f1'][grid.best_index_]:.4f}\")\n",
    "print(f\"✅ Accuracy medio:       {grid.cv_results_['mean_test_accuracy'][grid.best_index_]:.4f}\")\n",
    "print(f\"✅ Recall medio:         {grid.cv_results_['mean_test_recall'][grid.best_index_]:.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1b6ca13",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🔹 Evaluación en TRAIN:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      0.99      0.99       571\n",
      "           1       0.99      0.99      0.99       693\n",
      "\n",
      "    accuracy                           0.99      1264\n",
      "   macro avg       0.99      0.99      0.99      1264\n",
      "weighted avg       0.99      0.99      0.99      1264\n",
      "\n",
      "🔹 Evaluación en VALIDACIÓN:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      0.98      0.99       143\n",
      "           1       0.98      0.99      0.99       174\n",
      "\n",
      "    accuracy                           0.99       317\n",
      "   macro avg       0.99      0.99      0.99       317\n",
      "weighted avg       0.99      0.99      0.99       317\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.svm import SVC\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import classification_report\n",
    "import numpy as np\n",
    "\n",
    "# Cargar datos\n",
    "data_trainval = np.load(\"deepfake_trainval.npz\")\n",
    "X = data_trainval['X']\n",
    "y = data_trainval['y']\n",
    "\n",
    "# 1. Dividir en entrenamiento y validación (80/20)\n",
    "X_train, X_val, y_train, y_val = train_test_split(\n",
    "    X, y, test_size=0.2, random_state=42, stratify=y\n",
    ")\n",
    "\n",
    "# 2. Escalar los datos\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_val_scaled = scaler.transform(X_val)\n",
    "\n",
    "# 3. Crear y entrenar modelo\n",
    "svm = SVC(C = 10, degree = 2, gamma = 0.1, kernel = 'rbf', random_state=42)\n",
    "svm.fit(X_train_scaled, y_train)\n",
    "\n",
    "# 4. Evaluar en entrenamiento y validación\n",
    "print(\"🔹 Evaluación en TRAIN:\")\n",
    "print(classification_report(y_train, svm.predict(X_train_scaled)))\n",
    "\n",
    "print(\"🔹 Evaluación en VALIDACIÓN:\")\n",
    "print(classification_report(y_val, svm.predict(X_val_scaled)))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "17fc669d",
   "metadata": {},
   "source": [
    "Neural Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "8a116883",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🔹 Evaluación en TRAIN:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.71      0.58      0.64       571\n",
      "           1       0.70      0.81      0.75       693\n",
      "\n",
      "    accuracy                           0.70      1264\n",
      "   macro avg       0.70      0.69      0.69      1264\n",
      "weighted avg       0.70      0.70      0.70      1264\n",
      "\n",
      "🔹 Evaluación en VALIDACIÓN:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.65      0.62      0.64       143\n",
      "           1       0.70      0.72      0.71       174\n",
      "\n",
      "    accuracy                           0.68       317\n",
      "   macro avg       0.67      0.67      0.67       317\n",
      "weighted avg       0.68      0.68      0.68       317\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.model_selection import train_test_split\n",
    "import numpy as np\n",
    "\n",
    "# Cargar datos\n",
    "data_trainval = np.load(\"deepfake_trainval.npz\")\n",
    "X = data_trainval['X']\n",
    "y = data_trainval['y']\n",
    "\n",
    "# 1. Dividir en entrenamiento y validación (80/20)\n",
    "X_train, X_val, y_train, y_val = train_test_split(\n",
    "    X, y, test_size=0.2, random_state=42, stratify=y\n",
    ")\n",
    "\n",
    "# 2. Escalar los datos\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_val_scaled = scaler.transform(X_val)\n",
    "\n",
    "# 3. Definir la red neuronal\n",
    "class SimpleNN(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size=32):\n",
    "        super(SimpleNN, self).__init__()\n",
    "        self.fc1 = nn.Linear(input_size, hidden_size)\n",
    "        self.relu = nn.ReLU()\n",
    "        self.fc2 = nn.Linear(hidden_size, 1)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        x = self.fc1(x)\n",
    "        x = self.relu(x)\n",
    "        x = self.fc2(x)\n",
    "        return x  # Usaremos BCEWithLogitsLoss\n",
    "\n",
    "# 4. Preparar tensores\n",
    "X_train_tensor = torch.tensor(X_train_scaled, dtype=torch.float32)\n",
    "y_train_tensor = torch.tensor(y_train.reshape(-1, 1), dtype=torch.float32)\n",
    "\n",
    "X_val_tensor = torch.tensor(X_val_scaled, dtype=torch.float32)\n",
    "y_val_tensor = torch.tensor(y_val.reshape(-1, 1), dtype=torch.float32)\n",
    "\n",
    "# 5. Inicializar modelo, pérdida y optimizador\n",
    "model = SimpleNN(input_size=X_train.shape[1], hidden_size=32)\n",
    "criterion = nn.BCEWithLogitsLoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
    "\n",
    "# 6. Entrenamiento\n",
    "epochs = 50\n",
    "for epoch in range(epochs):\n",
    "    model.train()\n",
    "    optimizer.zero_grad()\n",
    "    outputs = model(X_train_tensor)\n",
    "    loss = criterion(outputs, y_train_tensor)\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "\n",
    "# 7. Evaluación en entrenamiento\n",
    "model.eval()\n",
    "with torch.no_grad():\n",
    "    outputs_train = model(X_train_tensor)\n",
    "    probs_train = torch.sigmoid(outputs_train).numpy()\n",
    "    y_pred_train = (probs_train > 0.5).astype(int).flatten()\n",
    "\n",
    "print(\"🔹 Evaluación en TRAIN:\")\n",
    "print(classification_report(y_train, y_pred_train))\n",
    "\n",
    "# 8. Evaluación en validación\n",
    "with torch.no_grad():\n",
    "    outputs_val = model(X_val_tensor)\n",
    "    probs_val = torch.sigmoid(outputs_val).numpy()\n",
    "    y_pred_val = (probs_val > 0.5).astype(int).flatten()\n",
    "\n",
    "print(\"🔹 Evaluación en VALIDACIÓN:\")\n",
    "print(classification_report(y_val, y_pred_val))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "486f035d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             0         1         2         3         4         5         6   \\\n",
      "label                                                                         \n",
      "0      0.040483  0.024919  0.013965  0.010321  0.007772  0.006414  0.005606   \n",
      "1      0.043586  0.026253  0.014277  0.010514  0.008016  0.006429  0.005643   \n",
      "\n",
      "             7         8         9   ...        16        17        18  \\\n",
      "label                                ...                                 \n",
      "0      0.006321  0.007432  0.009412  ...  0.008068  0.007188  0.006193   \n",
      "1      0.006119  0.007086  0.009069  ...  0.008076  0.007405  0.006430   \n",
      "\n",
      "             19        20        21        22        23        24        25  \n",
      "label                                                                        \n",
      "0      0.006667  0.007480  0.010137  0.015548  0.020548  0.284162  0.349465  \n",
      "1      0.007130  0.007864  0.010783  0.016176  0.020717  0.268121  0.358998  \n",
      "\n",
      "[2 rows x 26 columns]\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Calcular estadísticas básicas por clase\n",
    "import pandas as pd\n",
    "df_train = pd.DataFrame(X_train)\n",
    "df_train['label'] = y_train\n",
    "print(df_train.groupby('label').mean())  # ¿Hay features con medias muy distintas?\n",
    "\n",
    "# Graficar distribuciones (ejemplo para 1 feature)\n",
    "import matplotlib.pyplot as plt\n",
    "plt.hist(X_train_selected[y_train == 0][:, 0], alpha=0.5, label='Real (0)')\n",
    "plt.hist(X_train_selected[y_train == 1][:, 0], alpha=0.5, label='Fake (1)')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
