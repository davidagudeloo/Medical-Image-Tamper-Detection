{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "6fd4f2d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "# Cargar el archivo\n",
    "data = np.load(\"df-deepfake.npz\")\n",
    "\n",
    "# Acceder a los arrays\n",
    "X = data['X']\n",
    "y = data['y']\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "6570d3cc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train+Val shape: (1581, 40), Test shape: (396, 40)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Paso 1: dividir en entrenamiento+validaci√≥n y test\n",
    "X, X_test, y, y_test = train_test_split(\n",
    "    X, y, test_size=0.20, random_state=50, stratify=y  # stratify mantiene proporciones\n",
    ")\n",
    "\n",
    "# Paso 2: guardar el test para despu√©s\n",
    "np.savez_compressed(\"deepfake_trainval.npz\", X=X, y=y)\n",
    "np.savez_compressed(\"deepfake_test.npz\", X=X_test, y=y_test)\n",
    "\n",
    "# Paso 3: continuar con entrenamiento/validaci√≥n usando X_trainval, y_trainval\n",
    "print(f\"Train+Val shape: {X.shape}, Test shape: {X_test.shape}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "f725c516",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üîç Mejor combinaci√≥n de hiperpar√°metros: {'C': 0.01, 'penalty': 'l2', 'solver': 'lbfgs'}\n",
      "üìà Mejor F1-score (CV): 0.7362\n",
      "‚úÖ Accuracy medio: 0.6768\n",
      "‚úÖ Recall medio:   0.8235\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "import numpy as np\n",
    "\n",
    "# Cargar datos\n",
    "data_train = np.load(\"deepfake_trainval.npz\")\n",
    "X = data_train['X']\n",
    "y = data_train['y']\n",
    "\n",
    "# Escalar manualmente\n",
    "scaler = StandardScaler()\n",
    "X_scaled = scaler.fit_transform(X)\n",
    "\n",
    "# Modelo base\n",
    "lr = LogisticRegression(max_iter=1000)\n",
    "\n",
    "# Definir grilla de hiperpar√°metros\n",
    "param_grid = {\n",
    "    'C': [0.01, 0.1, 1, 10, 100],             # Regularizaci√≥n\n",
    "    'solver': ['lbfgs', 'liblinear'],         # Algoritmos\n",
    "    'penalty': ['l2']                         # Tipo de penalizaci√≥n (solo 'l2' es compatible con lbfgs y liblinear)\n",
    "}\n",
    "\n",
    "# M√©tricas para evaluar\n",
    "scoring = {\n",
    "    'accuracy': 'accuracy',\n",
    "    'recall': 'recall',\n",
    "    'f1': 'f1'\n",
    "}\n",
    "\n",
    "# Grid Search con CV\n",
    "grid = GridSearchCV(estimator=lr, param_grid=param_grid, cv=5,\n",
    "                    scoring=scoring, refit='f1', return_train_score=False)\n",
    "\n",
    "# Entrenar\n",
    "grid.fit(X_scaled, y)\n",
    "\n",
    "# Resultados\n",
    "print(\"üîç Mejor combinaci√≥n de hiperpar√°metros:\", grid.best_params_)\n",
    "print(f\"üìà Mejor F1-score (CV): {grid.best_score_:.4f}\")\n",
    "\n",
    "# Puedes imprimir m√°s m√©tricas si deseas:\n",
    "means = grid.cv_results_\n",
    "print(f\"‚úÖ Accuracy medio: {means['mean_test_accuracy'][grid.best_index_]:.4f}\")\n",
    "print(f\"‚úÖ Recall medio:   {means['mean_test_recall'][grid.best_index_]:.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "31c58bcd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üîπ Evaluaci√≥n en TRAIN:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.70      0.51      0.59       571\n",
      "           1       0.67      0.82      0.74       693\n",
      "\n",
      "    accuracy                           0.68      1264\n",
      "   macro avg       0.69      0.67      0.66      1264\n",
      "weighted avg       0.69      0.68      0.67      1264\n",
      "\n",
      "üîπ Evaluaci√≥n en VALIDACI√ìN:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.71      0.50      0.59       143\n",
      "           1       0.67      0.83      0.74       174\n",
      "\n",
      "    accuracy                           0.68       317\n",
      "   macro avg       0.69      0.67      0.67       317\n",
      "weighted avg       0.69      0.68      0.67       317\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import classification_report\n",
    "import numpy as np\n",
    "\n",
    "# Cargar datos\n",
    "data_trainval = np.load(\"deepfake_trainval.npz\")\n",
    "X = data_trainval['X']\n",
    "y = data_trainval['y']\n",
    "\n",
    "# 1. Dividir en entrenamiento y validaci√≥n (80/20)\n",
    "X_train, X_val, y_train, y_val = train_test_split(\n",
    "    X, y, test_size=0.2, random_state=42, stratify=y\n",
    ")\n",
    "\n",
    "# 2. Escalar los datos\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_val_scaled = scaler.transform(X_val)\n",
    "\n",
    "# 3. Crear y entrenar modelo con los hiperpar√°metros √≥ptimos\n",
    "lr = LogisticRegression(C=0.01, penalty='l2', solver='lbfgs', max_iter=1000)\n",
    "lr.fit(X_train_scaled, y_train)\n",
    "\n",
    "# 4. Evaluar en entrenamiento y validaci√≥n\n",
    "print(\"üîπ Evaluaci√≥n en TRAIN:\")\n",
    "print(classification_report(y_train, lr.predict(X_train_scaled)))\n",
    "\n",
    "print(\"üîπ Evaluaci√≥n en VALIDACI√ìN:\")\n",
    "print(classification_report(y_val, lr.predict(X_val_scaled)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "d3031f82",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 16 candidates, totalling 80 fits\n",
      "üîç Mejor combinaci√≥n de hiperpar√°metros: {'metric': 'euclidean', 'n_neighbors': 5, 'weights': 'distance'}\n",
      "üìà Mejor F1-score (CV): 0.9751\n",
      "‚úÖ Accuracy medio:       0.9728\n",
      "‚úÖ Recall medio:         0.9712\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import numpy as np\n",
    "\n",
    "# Cargar datos\n",
    "data_train = np.load(\"deepfake_trainval.npz\")\n",
    "X = data_train['X']\n",
    "y = data_train['y']\n",
    "\n",
    "# Escalar\n",
    "scaler = StandardScaler()\n",
    "X_scaled = scaler.fit_transform(X)\n",
    "\n",
    "# Modelo base\n",
    "knn = KNeighborsClassifier()\n",
    "\n",
    "# Grilla de hiperpar√°metros\n",
    "param_grid = {\n",
    "    'n_neighbors': [ 5, 10, 15, 20],\n",
    "    'weights': ['uniform', 'distance'],\n",
    "    'metric': ['euclidean', 'manhattan']\n",
    "}\n",
    "\n",
    "# Scoring m√∫ltiple\n",
    "scoring = {\n",
    "    'accuracy': 'accuracy',\n",
    "    'recall': 'recall',\n",
    "    'f1': 'f1'\n",
    "}\n",
    "\n",
    "# GridSearch con m√∫ltiples m√©tricas\n",
    "grid = GridSearchCV(\n",
    "    estimator=knn,\n",
    "    param_grid=param_grid,\n",
    "    scoring=scoring,\n",
    "    refit='f1',  # el mejor se elige por f1\n",
    "    cv=5,\n",
    "    n_jobs=-1,\n",
    "    verbose=1\n",
    ")\n",
    "\n",
    "# Entrenar\n",
    "grid.fit(X_scaled, y)\n",
    "\n",
    "# Resultados\n",
    "print(\"üîç Mejor combinaci√≥n de hiperpar√°metros:\", grid.best_params_)\n",
    "print(f\"üìà Mejor F1-score (CV): {grid.cv_results_['mean_test_f1'][grid.best_index_]:.4f}\")\n",
    "print(f\"‚úÖ Accuracy medio:       {grid.cv_results_['mean_test_accuracy'][grid.best_index_]:.4f}\")\n",
    "print(f\"‚úÖ Recall medio:         {grid.cv_results_['mean_test_recall'][grid.best_index_]:.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "fa2830fb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üîπ Evaluaci√≥n en TRAIN:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00       571\n",
      "           1       1.00      1.00      1.00       693\n",
      "\n",
      "    accuracy                           1.00      1264\n",
      "   macro avg       1.00      1.00      1.00      1264\n",
      "weighted avg       1.00      1.00      1.00      1264\n",
      "\n",
      "üîπ Evaluaci√≥n en VALIDACI√ìN:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      0.99      0.99       143\n",
      "           1       0.99      0.99      0.99       174\n",
      "\n",
      "    accuracy                           0.99       317\n",
      "   macro avg       0.99      0.99      0.99       317\n",
      "weighted avg       0.99      0.99      0.99       317\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import classification_report\n",
    "import numpy as np\n",
    "\n",
    "# Cargar datos\n",
    "data_trainval = np.load(\"deepfake_trainval.npz\")\n",
    "X = data_trainval['X']\n",
    "y = data_trainval['y']\n",
    "\n",
    "# 1. Dividir en entrenamiento y validaci√≥n (80/20)\n",
    "X_train, X_val, y_train, y_val = train_test_split(\n",
    "    X, y, test_size=0.2, random_state=42, stratify=y\n",
    ")\n",
    "\n",
    "# 2. Escalar los datos\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_val_scaled = scaler.transform(X_val)\n",
    "\n",
    "# 3. Crear y entrenar modelo\n",
    "knn = KNeighborsClassifier(metric = 'euclidean', n_neighbors= 5, weights= 'distance')\n",
    "knn.fit(X_train_scaled, y_train)\n",
    "\n",
    "# 4. Evaluar en entrenamiento y validaci√≥n\n",
    "print(\"üîπ Evaluaci√≥n en TRAIN:\")\n",
    "print(classification_report(y_train, knn.predict(X_train_scaled)))\n",
    "\n",
    "print(\"üîπ Evaluaci√≥n en VALIDACI√ìN:\")\n",
    "print(classification_report(y_val, knn.predict(X_val_scaled)))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9450acfc",
   "metadata": {},
   "source": [
    "Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "db0ac7dc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 24 candidates, totalling 120 fits\n",
      "üîç Mejor combinaci√≥n de hiperpar√°metros: {'max_depth': 15, 'min_samples_leaf': 2, 'min_samples_split': 2, 'n_estimators': 100}\n",
      "üìà Mejor F1-score (CV): 0.9696\n",
      "‚úÖ Accuracy medio:       0.9665\n",
      "‚úÖ Recall medio:         0.9723\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import numpy as np\n",
    "\n",
    "# Cargar datos\n",
    "data_train = np.load(\"deepfake_trainval.npz\")\n",
    "X = data_train['X']\n",
    "y = data_train['y']\n",
    "\n",
    "# Escalar los datos\n",
    "scaler = StandardScaler()\n",
    "X_scaled = scaler.fit_transform(X)\n",
    "\n",
    "# Definir modelo base\n",
    "rf = RandomForestClassifier(random_state=42)\n",
    "\n",
    "# Definir la grilla de hiperpar√°metros\n",
    "param_grid = {\n",
    "    'n_estimators': [100, 200],\n",
    "    'max_depth': [5, 10, 15],\n",
    "    'min_samples_split': [2, 5],\n",
    "    'min_samples_leaf': [1, 2]\n",
    "}\n",
    "\n",
    "scoring = {\n",
    "    'accuracy': 'accuracy',\n",
    "    'recall': 'recall',\n",
    "    'f1': 'f1'\n",
    "}\n",
    "\n",
    "# Crear GridSearchCV\n",
    "grid = GridSearchCV(\n",
    "    estimator=rf,\n",
    "    param_grid=param_grid,\n",
    "    scoring=scoring,  # tambi√©n puedes usar 'recall' si priorizas eso\n",
    "    cv=5,\n",
    "    refit='f1',  # el mejor se elige por f1\n",
    "    n_jobs=-1,\n",
    "    verbose=1\n",
    ")\n",
    "\n",
    "# Ejecutar b√∫squeda\n",
    "grid.fit(X_scaled, y)\n",
    "\n",
    "# Resultados\n",
    "print(\"üîç Mejor combinaci√≥n de hiperpar√°metros:\", grid.best_params_)\n",
    "print(f\"üìà Mejor F1-score (CV): {grid.cv_results_['mean_test_f1'][grid.best_index_]:.4f}\")\n",
    "print(f\"‚úÖ Accuracy medio:       {grid.cv_results_['mean_test_accuracy'][grid.best_index_]:.4f}\")\n",
    "print(f\"‚úÖ Recall medio:         {grid.cv_results_['mean_test_recall'][grid.best_index_]:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "b9c69e43",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üîπ Evaluaci√≥n en TRAIN:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00       571\n",
      "           1       1.00      1.00      1.00       693\n",
      "\n",
      "    accuracy                           1.00      1264\n",
      "   macro avg       1.00      1.00      1.00      1264\n",
      "weighted avg       1.00      1.00      1.00      1264\n",
      "\n",
      "üîπ Evaluaci√≥n en VALIDACI√ìN:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      0.97      0.98       143\n",
      "           1       0.98      0.99      0.99       174\n",
      "\n",
      "    accuracy                           0.98       317\n",
      "   macro avg       0.99      0.98      0.98       317\n",
      "weighted avg       0.98      0.98      0.98       317\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import classification_report\n",
    "import numpy as np\n",
    "\n",
    "# Cargar datos\n",
    "data_trainval = np.load(\"deepfake_trainval.npz\")\n",
    "X = data_trainval['X']\n",
    "y = data_trainval['y']\n",
    "\n",
    "# 1. Dividir en entrenamiento y validaci√≥n (80/20)\n",
    "X_train, X_val, y_train, y_val = train_test_split(\n",
    "    X, y, test_size=0.2, random_state=42, stratify=y\n",
    ")\n",
    "\n",
    "# 2. Escalar los datos\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_val_scaled = scaler.transform(X_val)\n",
    "\n",
    "# 3. Crear y entrenar modelo\n",
    "rf = RandomForestClassifier(max_depth= 15, min_samples_leaf= 2, min_samples_split= 2, n_estimators = 100, random_state=42)\n",
    "rf.fit(X_train_scaled, y_train)\n",
    "\n",
    "# 4. Evaluar en entrenamiento y validaci√≥n\n",
    "print(\"üîπ Evaluaci√≥n en TRAIN:\")\n",
    "print(classification_report(y_train, rf.predict(X_train_scaled)))\n",
    "\n",
    "print(\"üîπ Evaluaci√≥n en VALIDACI√ìN:\")\n",
    "print(classification_report(y_val, rf.predict(X_val_scaled)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "78f460c2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy promedio (CV): 0.8823\n",
      "Recall promedio (CV):   0.9169\n",
      "F1-score promedio (CV): 0.8951\n"
     ]
    }
   ],
   "source": [
    "from sklearn.svm import SVC\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import numpy as np\n",
    "\n",
    "# Cargar datos\n",
    "data_train = np.load(\"deepfake_trainval.npz\")\n",
    "X = data_train['X']\n",
    "y = data_train['y']\n",
    "\n",
    "data_test = np.load(\"deepfake_test.npz\")\n",
    "X_test = data_test['X']\n",
    "y_test = data_test['y']\n",
    "\n",
    "# Escalar datos (muy importante para SVM)\n",
    "scaler = StandardScaler()\n",
    "X_scaled = scaler.fit_transform(X)\n",
    "X_test_scaled = scaler.transform(X_test)\n",
    "\n",
    "# Crear modelo SVM (con kernel RBF por defecto)\n",
    "svm = SVC(kernel='rbf', C=2, gamma='scale', random_state=42)\n",
    "\n",
    "# Validaci√≥n cruzada (usando m√∫ltiples m√©tricas)\n",
    "scoring = {\n",
    "    'accuracy': 'accuracy',\n",
    "    'recall': 'recall', \n",
    "    'f1': 'f1'\n",
    "}\n",
    "\n",
    "results = cross_validate(svm, X_scaled, y, cv=5, scoring=scoring)\n",
    "\n",
    "# Mostrar resultados promedio\n",
    "print(f\"Accuracy promedio (CV): {results['test_accuracy'].mean():.4f}\")\n",
    "print(f\"Recall promedio (CV):   {results['test_recall'].mean():.4f}\")\n",
    "print(f\"F1-score promedio (CV): {results['test_f1'].mean():.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "d1b6ca13",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üîπ Evaluaci√≥n en TRAIN:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.90      0.84      0.87       571\n",
      "           1       0.87      0.92      0.90       693\n",
      "\n",
      "    accuracy                           0.89      1264\n",
      "   macro avg       0.89      0.88      0.88      1264\n",
      "weighted avg       0.89      0.89      0.88      1264\n",
      "\n",
      "üîπ Evaluaci√≥n en VALIDACI√ìN:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.90      0.83      0.86       143\n",
      "           1       0.87      0.93      0.89       174\n",
      "\n",
      "    accuracy                           0.88       317\n",
      "   macro avg       0.88      0.88      0.88       317\n",
      "weighted avg       0.88      0.88      0.88       317\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.svm import SVC\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import classification_report\n",
    "import numpy as np\n",
    "\n",
    "# Cargar datos\n",
    "data_trainval = np.load(\"deepfake_trainval.npz\")\n",
    "X = data_trainval['X']\n",
    "y = data_trainval['y']\n",
    "\n",
    "# 1. Dividir en entrenamiento y validaci√≥n (80/20)\n",
    "X_train, X_val, y_train, y_val = train_test_split(\n",
    "    X, y, test_size=0.2, random_state=42, stratify=y\n",
    ")\n",
    "\n",
    "# 2. Escalar los datos\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_val_scaled = scaler.transform(X_val)\n",
    "\n",
    "# 3. Crear y entrenar modelo\n",
    "svm = SVC(kernel='rbf', C=2, gamma='scale', random_state=42)\n",
    "svm.fit(X_train_scaled, y_train)\n",
    "\n",
    "# 4. Evaluar en entrenamiento y validaci√≥n\n",
    "print(\"üîπ Evaluaci√≥n en TRAIN:\")\n",
    "print(classification_report(y_train, svm.predict(X_train_scaled)))\n",
    "\n",
    "print(\"üîπ Evaluaci√≥n en VALIDACI√ìN:\")\n",
    "print(classification_report(y_val, svm.predict(X_val_scaled)))\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
