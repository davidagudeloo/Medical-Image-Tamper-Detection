{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 194,
   "id": "27cc7df1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Train: (5446, 512), Val: (481, 512), Test Normales: (815, 512)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import GroupShuffleSplit\n",
    "import numpy as np\n",
    "\n",
    "# Cargar normales\n",
    "data = np.load(\"data_oneclass_resnet_normales.npz\", allow_pickle=True)\n",
    "X = data['X']\n",
    "y = data['y']  # Todo ceros\n",
    "groups = data['groups']\n",
    "\n",
    "# üîπ Primer split: 80% Train, 20% Val+Test\n",
    "gss1 = GroupShuffleSplit(n_splits=1, test_size=0.2, random_state=42)\n",
    "train_idx, val_test_idx = next(gss1.split(X, y, groups=groups))\n",
    "\n",
    "X_train, X_val_test = X[train_idx], X[val_test_idx]\n",
    "y_train, y_val_test = y[train_idx], y[val_test_idx]\n",
    "groups_train, groups_val_test = groups[train_idx], groups[val_test_idx]\n",
    "\n",
    "# üîπ Segundo split: 50% Val, 50% Test dentro de Val+Test\n",
    "gss2 = GroupShuffleSplit(n_splits=1, test_size=0.8, random_state=42)\n",
    "val_idx, test_idx = next(gss2.split(X_val_test, y_val_test, groups=groups_val_test))\n",
    "\n",
    "X_val, X_test_normales = X_val_test[val_idx], X_val_test[test_idx]\n",
    "y_val, y_test_normales = y_val_test[val_idx], y_val_test[test_idx]\n",
    "groups_val, groups_test_normales = groups_val_test[val_idx], groups_val_test[test_idx]\n",
    "\n",
    "print(f\"‚úÖ Train: {X_train.shape}, Val: {X_val.shape}, Test Normales: {X_test_normales.shape}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 195,
   "id": "9be77c86",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cargar anormales\n",
    "data_anormales = np.load(\"data_oneclass_resnet_anormales.npz\", allow_pickle=True)\n",
    "X_anormales = data_anormales['X']\n",
    "y_anormales = data_anormales['y']  # Todo unos\n",
    "groups_anormales = data_anormales['groups']\n",
    "\n",
    "# Split 50% Val, 50% Test\n",
    "gss3 = GroupShuffleSplit(n_splits=1, test_size=0.5, random_state=42)\n",
    "anom_val_idx, anom_test_idx = next(gss3.split(X_anormales, y_anormales, groups=groups_anormales))\n",
    "\n",
    "X_anom_val, X_anom_test = X_anormales[anom_val_idx], X_anormales[anom_test_idx]\n",
    "y_anom_val, y_anom_test = y_anormales[anom_val_idx], y_anormales[anom_test_idx]\n",
    "groups_anom_val, groups_anom_test = groups_anormales[anom_val_idx], groups_anormales[anom_test_idx]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 196,
   "id": "9af7114d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Validaci√≥n: normales + anormales\n",
    "X_val_total = np.concatenate([X_val, X_anom_val])\n",
    "y_val_total = np.concatenate([y_val, y_anom_val])\n",
    "groups_val_total = np.concatenate([groups_val, groups_anom_val])\n",
    "\n",
    "# Barajar aleatoriamente\n",
    "rng = np.random.default_rng(42)  # Para reproducibilidad\n",
    "indices = np.arange(X_val_total.shape[0])\n",
    "rng.shuffle(indices)\n",
    "\n",
    "# Reordenar\n",
    "X_val_total = X_val_total[indices]\n",
    "y_val_total = y_val_total[indices]\n",
    "groups_val_total = groups_val_total[indices]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 197,
   "id": "9befc7ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test_total = np.concatenate([X_test_normales, X_anom_test])\n",
    "y_test_total = np.concatenate([y_test_normales, y_anom_test])\n",
    "groups_test_total = np.concatenate([groups_test_normales, groups_anom_test])\n",
    "\n",
    "rng = np.random.default_rng(42)  # Puedes usar el mismo o diferente seed\n",
    "indices = np.arange(X_test_total.shape[0])\n",
    "rng.shuffle(indices)\n",
    "\n",
    "X_test_total = X_test_total[indices]\n",
    "y_test_total = y_test_total[indices]\n",
    "groups_test_total = groups_test_total[indices]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2b724464",
   "metadata": {},
   "source": [
    "Entrenamiento OneClass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "id": "4752e777",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Shape final despu√©s de RFE: (5446, 25)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.feature_selection import VarianceThreshold\n",
    "from sklearn.feature_selection import RFE\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "# Escalado\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_val_scaled = scaler.transform(X_val_total)\n",
    "X_test_scaled = scaler.transform(X_test_total)\n",
    "\n",
    "#Seleccion caracter√≠sticas\n",
    "\n",
    "# Estimador base\n",
    "estimator = RandomForestClassifier(n_estimators=200, random_state=42)\n",
    "\n",
    "\n",
    "rfe = RFE(estimator=estimator, n_features_to_select=25, step=0.1)\n",
    "\n",
    "# Ajustar en entrenamiento\n",
    "rfe.fit(X_train_scaled, y_train)\n",
    "\n",
    "# Transformar datasets\n",
    "X_train_reducido = rfe.transform(X_train_scaled)\n",
    "X_val_reducido = rfe.transform(X_val_scaled)\n",
    "X_test_reducido = rfe.transform(X_test_scaled)\n",
    "\n",
    "print(f\"‚úÖ Shape final despu√©s de RFE: {X_train_reducido.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 212,
   "id": "0d1c62e5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üîç Evaluaci√≥n en VALIDACI√ìN:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "      Normal       0.97      1.00      0.98       481\n",
      "     An√≥malo       1.00      0.11      0.19        19\n",
      "\n",
      "    accuracy                           0.97       500\n",
      "   macro avg       0.98      0.55      0.59       500\n",
      "weighted avg       0.97      0.97      0.95       500\n",
      "\n",
      "[[481   0]\n",
      " [ 17   2]]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.svm import OneClassSVM\n",
    "\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "\n",
    "# Escalado\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_val_scaled = scaler.transform(X_val_total)\n",
    "X_test_scaled = scaler.transform(X_test_total)\n",
    "\n",
    "# Definir y entrenar el One-Class SVM\n",
    "oc_svm = OneClassSVM(kernel='sigmoid', gamma='auto', nu=0.04)\n",
    "oc_svm.fit(X_train_scaled)\n",
    "\n",
    "# Predicci√≥n en validaci√≥n\n",
    "y_val_pred = oc_svm.predict(X_val_scaled)\n",
    "y_val_pred = np.where(y_val_pred == 1, 0, 1)  # 1 normal ‚Üí 0, -1 an√≥malo ‚Üí 1\n",
    "\n",
    "# Evaluaci√≥n\n",
    "print(\"üîç Evaluaci√≥n en VALIDACI√ìN:\")\n",
    "print(classification_report(y_val_total, y_val_pred, target_names=[\"Normal\", \"An√≥malo\"]))\n",
    "print(confusion_matrix(y_val_total, y_val_pred))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 256,
   "id": "846dc1e2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üîç Evaluaci√≥n en VALIDACI√ìN:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "      Normal       0.96      0.99      0.98       481\n",
      "     An√≥malo       0.25      0.05      0.09        19\n",
      "\n",
      "    accuracy                           0.96       500\n",
      "   macro avg       0.61      0.52      0.53       500\n",
      "weighted avg       0.94      0.96      0.94       500\n",
      "\n",
      "[[478   3]\n",
      " [ 18   1]]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import IsolationForest\n",
    "\n",
    "iso = IsolationForest(n_estimators=10, contamination=0.03, random_state=10)\n",
    "iso.fit(X_train_scaled)\n",
    "\n",
    "y_val_pred = iso.predict(X_val_scaled)\n",
    "y_val_pred = np.where(y_val_pred == 1, 0, 1)  # 1 normal ‚Üí 0, -1 an√≥malo ‚Üí 1\n",
    "\n",
    "# Evaluaci√≥n\n",
    "print(\"üîç Evaluaci√≥n en VALIDACI√ìN:\")\n",
    "print(classification_report(y_val_total, y_val_pred, target_names=[\"Normal\", \"An√≥malo\"]))\n",
    "print(confusion_matrix(y_val_total, y_val_pred))\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
