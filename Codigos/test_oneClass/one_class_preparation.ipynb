{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "75352663",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "import cv2\n",
    "import numpy as np\n",
    "import pydicom\n",
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "from skimage.feature import local_binary_pattern\n",
    "from skimage.feature import graycomatrix, graycoprops"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "6dcc1e9b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cargar dataset original\n",
    "df = pd.read_csv('labels.csv', sep=';')\n",
    "labels = df.copy()\n",
    "# Dropear las filas donde type == 'FB'\n",
    "labels = labels[labels['type'] != 'FB'].reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "7cc89969",
   "metadata": {},
   "outputs": [],
   "source": [
    "labels.to_csv('labels_oneclass.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "536ad186",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Procesando imágenes: 100%|██████████| 92/92 [05:08<00:00,  3.35s/it] \n"
     ]
    }
   ],
   "source": [
    "\n",
    "def dcm_a_png(dcm_path, png_path, window_min=-1000, window_max=400):\n",
    "    try:\n",
    "        ds = pydicom.dcmread(dcm_path)\n",
    "        img = ds.pixel_array.astype(np.float32)\n",
    "        img = np.clip(img, window_min, window_max)\n",
    "        img = ((img - window_min) / (window_max - window_min)) * 255.0\n",
    "        img = img.astype(np.uint8)\n",
    "        os.makedirs(os.path.dirname(png_path), exist_ok=True)\n",
    "        cv2.imwrite(png_path, img)\n",
    "    except Exception as e:\n",
    "        print(f\"Error procesando {dcm_path}: {e}\")\n",
    "\n",
    "def convertir_a_png_condicional(df, input_dir='Experiments', output_dir='output_png',\n",
    "                                window_min=-1000, window_max=400):\n",
    "    for idx, row in tqdm(df.iterrows(), total=df.shape[0], desc=\"Procesando imágenes\"):\n",
    "        tipo = row['type']\n",
    "        uuid = row['uuid']\n",
    "        slice_num = row['slice']\n",
    "\n",
    "        folder = os.path.join(input_dir, str(uuid))\n",
    "        \n",
    "        if not os.path.exists(folder):\n",
    "            print(f\"Carpeta no encontrada: {folder}\")\n",
    "            continue\n",
    "        \n",
    "        if tipo in ['TB', 'TM']:\n",
    "            # Procesar todos los .dcm del paciente\n",
    "            for file in os.listdir(folder):\n",
    "                if file.endswith('.dcm'):\n",
    "                    dcm_path = os.path.join(folder, file)\n",
    "                    png_name = os.path.splitext(file)[0] + '.png'\n",
    "                    png_path = os.path.join(output_dir, str(uuid), png_name)\n",
    "                    dcm_a_png(dcm_path, png_path, window_min, window_max)\n",
    "\n",
    "        elif tipo == 'FM':\n",
    "            # Solo procesar el slice correspondiente\n",
    "            dcm_path = os.path.join(folder, f\"{slice_num}.dcm\")\n",
    "            png_path = os.path.join(output_dir, str(uuid), f\"{slice_num}.png\")\n",
    "            if os.path.exists(dcm_path):\n",
    "                dcm_a_png(dcm_path, png_path, window_min, window_max)\n",
    "            else:\n",
    "                print(f\"Slice no encontrado: {dcm_path}\")\n",
    "\n",
    "convertir_a_png_condicional(labels, input_dir='Experiments', output_dir='Experiments-OneClass')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "d6dd0310",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\JUAN\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\torchvision\\models\\_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
      "  warnings.warn(\n",
      "c:\\Users\\JUAN\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\torchvision\\models\\_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=ResNet18_Weights.IMAGENET1K_V1`. You can also use `weights=ResNet18_Weights.DEFAULT` to get the most up-to-date weights.\n",
      "  warnings.warn(msg)\n"
     ]
    }
   ],
   "source": [
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torchvision.models as models\n",
    "import torchvision.transforms as transforms\n",
    "\n",
    "def extraer_features_glcm(img):\n",
    "    # Configuración de GLCM\n",
    "    distances = [1]\n",
    "    angles = [0, np.pi/4, np.pi/2, 3*np.pi/4]\n",
    "\n",
    "    # ------ GLCM Features ------ #\n",
    "    glcm = graycomatrix(img, \n",
    "                        distances=distances, \n",
    "                        angles=angles, \n",
    "                        levels=256, \n",
    "                        symmetric=True, \n",
    "                        normed=True)\n",
    "    \n",
    "    contraste = graycoprops(glcm, 'contrast').flatten()\n",
    "    homogeneidad = graycoprops(glcm, 'homogeneity').flatten()\n",
    "    energia = graycoprops(glcm, 'energy').flatten()\n",
    "    correlacion = graycoprops(glcm, 'correlation').flatten()\n",
    "    entropia = -np.sum(glcm * np.log2(glcm + 1e-10), axis=(0, 1)).flatten()\n",
    "\n",
    "    return np.concatenate([contraste, homogeneidad, energia, correlacion, entropia])\n",
    "\n",
    "def extraer_features_lbp(img):\n",
    "     # Configuración de LBP\n",
    "    radius = 1\n",
    "    n_points = 8 * radius\n",
    "    method = 'uniform'  # Da un histograma de 59 bins con 8 vecinos\n",
    "\n",
    "    lbp = local_binary_pattern(img, n_points, radius, method)\n",
    "    hist, _ = np.histogram(lbp.ravel(), \n",
    "                           bins=np.arange(0, n_points + 3),\n",
    "                           range=(0, n_points + 2))\n",
    "    hist = hist.astype(\"float\")\n",
    "    hist /= (hist.sum() + 1e-6)  # Normalización\n",
    "\n",
    "    return hist\n",
    "\n",
    "# Configuración ResNet\n",
    "resnet = models.resnet18(pretrained=True)\n",
    "resnet.fc = nn.Identity()\n",
    "resnet.eval()\n",
    "\n",
    "preprocess = transforms.Compose([\n",
    "    transforms.ToPILImage(),\n",
    "    transforms.Resize(224),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
    "])\n",
    "\n",
    "def extraer_features_resnet(img):\n",
    "    if len(img.shape) == 2:\n",
    "        img = cv2.cvtColor(img, cv2.COLOR_GRAY2RGB)\n",
    "    \n",
    "    input_tensor = preprocess(img).unsqueeze(0)\n",
    "    with torch.no_grad():\n",
    "        features = resnet(input_tensor).numpy().flatten()\n",
    "    return features\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "81b3aa61",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 64/64 [15:07<00:00, 14.19s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ DataFrame final con shape: (6783, 32)\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "\n",
    "# ---------------- Configuración ---------------- #\n",
    "carpeta_png = 'Experiments-OneClass/'\n",
    "labels = pd.read_csv('labels_oneclass.csv')\n",
    "labels['label'] = labels['type'].apply(lambda x: 1 if x == 'FM' else 0)\n",
    "\n",
    "# Crear diccionario para lookup rápido\n",
    "dict_labels = {}\n",
    "for idx, row in labels.iterrows():\n",
    "    key = (str(row['uuid']), int(row['slice']))\n",
    "    dict_labels[key] = row['label']\n",
    "\n",
    "# Lista para guardar resultados\n",
    "lista_features = []\n",
    "\n",
    "# ---------------- Recorrido de todas las imágenes ---------------- #\n",
    "for uuid in tqdm(os.listdir(carpeta_png)):\n",
    "    uuid_path = os.path.join(carpeta_png, uuid)\n",
    "    if not os.path.isdir(uuid_path):\n",
    "        continue\n",
    "\n",
    "    for file in os.listdir(uuid_path):\n",
    "        if not file.endswith(\".png\"):\n",
    "            continue\n",
    "\n",
    "        slice_num = int(file.replace(\".png\", \"\"))\n",
    "\n",
    "        ruta_imagen = os.path.join(uuid_path, file)\n",
    "        img = cv2.imread(ruta_imagen, cv2.IMREAD_GRAYSCALE)\n",
    "\n",
    "        if img is None:\n",
    "            print(f\"Error cargando {ruta_imagen}\")\n",
    "            continue\n",
    "\n",
    "        # Buscar label\n",
    "        label = dict_labels.get((uuid, slice_num), 0)  # Por defecto 0 si no está listado\n",
    "\n",
    "        # Extraer features\n",
    "        features_concatenados = []\n",
    "        columnas = []\n",
    "\n",
    "        features_lbp = extraer_features_lbp(img)\n",
    "        features_concatenados = np.concatenate([features_concatenados, features_lbp])\n",
    "        columnas = np.concatenate([columnas,[f'lbp_hist_{i}' for i in range(features_lbp.shape[0])]])\n",
    "\n",
    "        features_glcm = extraer_features_glcm(img)\n",
    "        features_concatenados = np.concatenate([features_concatenados, features_glcm])\n",
    "        columnas = np.concatenate([columnas,[f'glcm_feat_{i}' for i in range(features_glcm.shape[0])]])\n",
    "\n",
    "        lista_features.append([uuid, slice_num, label] + features_concatenados.tolist())\n",
    "\n",
    "# ---------------- DataFrame final ---------------- #\n",
    "if isinstance(columnas, np.ndarray):\n",
    "    columnas = columnas.tolist()\n",
    "\n",
    "columnas_finales = ['uuid', 'slice', 'label'] + columnas\n",
    "df_features = pd.DataFrame(lista_features, columns=columnas_finales)\n",
    "\n",
    "# Eliminar columna slice si no la necesitas\n",
    "df_features = df_features.drop(columns=['slice'])\n",
    "\n",
    "# Reordenar columnas\n",
    "columnas_ordenadas = [col for col in df_features.columns if col not in ['uuid', 'label']] + ['uuid', 'label']\n",
    "df_features = df_features[columnas_ordenadas]\n",
    "\n",
    "print(f\"✅ DataFrame final con shape: {df_features.shape}\")\n",
    "\n",
    "df_features.to_pickle(\"data_oneclass.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "f081bf29",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🔧 Procesando imágenes...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Pacientes: 100%|██████████| 64/64 [07:05<00:00,  6.64s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ DataFrame final con shape: (6783, 514)\n"
     ]
    }
   ],
   "source": [
    "# ---------------- Cargar labels ---------------- #\n",
    "carpeta_png = 'Experiments-OneClass/'\n",
    "labels = pd.read_csv('labels_oneclass.csv')\n",
    "labels['label'] = labels['type'].apply(lambda x: 1 if x == 'FM' else 0)\n",
    "\n",
    "# Crear diccionario para lookup rápido\n",
    "dict_labels = {(str(row['uuid']), int(row['slice'])): row['label'] for idx, row in labels.iterrows()}\n",
    "\n",
    "lista_features = []\n",
    "\n",
    "# ---------------- Recorrido ---------------- #\n",
    "print(\"🔧 Procesando imágenes...\")\n",
    "\n",
    "for uuid in tqdm(os.listdir(carpeta_png), desc=\"Pacientes\"):\n",
    "    uuid_path = os.path.join(carpeta_png, uuid)\n",
    "    if not os.path.isdir(uuid_path):\n",
    "        continue\n",
    "\n",
    "    archivos = [f for f in os.listdir(uuid_path) if f.endswith(\".png\")]\n",
    "\n",
    "    for file in tqdm(archivos, desc=f\"Procesando {uuid}\", leave=False):\n",
    "        slice_num = int(file.replace(\".png\", \"\"))\n",
    "        ruta_imagen = os.path.join(uuid_path, file)\n",
    "        img = cv2.imread(ruta_imagen, cv2.IMREAD_GRAYSCALE)\n",
    "\n",
    "        if img is None:\n",
    "            print(f\"⚠️ Error cargando {ruta_imagen}\")\n",
    "            continue\n",
    "\n",
    "        label = dict_labels.get((uuid, slice_num), 0)\n",
    "\n",
    "        features_resnet = extraer_features_resnet(img)\n",
    "        lista_features.append([uuid, slice_num, label] + features_resnet.tolist())\n",
    "\n",
    "# ---------------- DataFrame final ---------------- #\n",
    "columnas_finales = ['uuid', 'slice', 'label'] + [f'resnet_feat_{i}' for i in range(512)]\n",
    "df_features = pd.DataFrame(lista_features, columns=columnas_finales)\n",
    "\n",
    "# Eliminar columna slice si no la necesitas\n",
    "df_features = df_features.drop(columns=['slice'])\n",
    "\n",
    "# Reordenar columnas\n",
    "columnas_ordenadas = [col for col in df_features.columns if col not in ['uuid', 'label']] + ['uuid', 'label']\n",
    "df_features = df_features[columnas_ordenadas]\n",
    "\n",
    "print(f\"✅ DataFrame final con shape: {df_features.shape}\")\n",
    "\n",
    "df_features.to_pickle(\"data_oneclass_resnet.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "f20dc9bb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Datasets guardados exitosamente.\n"
     ]
    }
   ],
   "source": [
    "X = np.array(df_features.drop(columns=['uuid', 'label']))\n",
    "y = np.array(df_features['label'])\n",
    "groups = np.array(df_features['uuid'])\n",
    "\n",
    "# Dataset completo\n",
    "np.savez_compressed(\"data_oneclass_completo.npz\", X=X, y=y, groups=groups)\n",
    "df_features.to_pickle(\"data_oneclass_completo.pkl\")\n",
    "\n",
    "# Solo normales\n",
    "mask_normales = y == 0\n",
    "X_normales = X[mask_normales]\n",
    "y_normales = y[mask_normales]\n",
    "groups_normales = groups[mask_normales]\n",
    "\n",
    "np.savez_compressed(\"data_oneclass_normales.npz\", X=X_normales, y=y_normales, groups=groups_normales)\n",
    "\n",
    "# Solo anormales\n",
    "mask_anormales = y == 1\n",
    "X_anormales = X[mask_anormales]\n",
    "y_anormales = y[mask_anormales]\n",
    "groups_anormales = groups[mask_anormales]\n",
    "\n",
    "np.savez_compressed(\"data_oneclass_anormales.npz\", X=X_anormales, y=y_anormales, groups=groups_anormales)\n",
    "\n",
    "print(\"✅ Datasets guardados exitosamente.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "56f4db66",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Datasets guardados exitosamente.\n"
     ]
    }
   ],
   "source": [
    "X = np.array(df_features.drop(columns=['uuid', 'label']))\n",
    "y = np.array(df_features['label'])\n",
    "groups = np.array(df_features['uuid'])\n",
    "\n",
    "# Dataset completo\n",
    "np.savez_compressed(\"data_oneclass_resnet_completo.npz\", X=X, y=y, groups=groups)\n",
    "df_features.to_pickle(\"data_oneclass_resnet_completo.pkl\")\n",
    "\n",
    "# Solo normales\n",
    "mask_normales = y == 0\n",
    "X_normales = X[mask_normales]\n",
    "y_normales = y[mask_normales]\n",
    "groups_normales = groups[mask_normales]\n",
    "\n",
    "np.savez_compressed(\"data_oneclass_resnet_normales.npz\", X=X_normales, y=y_normales, groups=groups_normales)\n",
    "\n",
    "# Solo anormales\n",
    "mask_anormales = y == 1\n",
    "X_anormales = X[mask_anormales]\n",
    "y_anormales = y[mask_anormales]\n",
    "groups_anormales = groups[mask_anormales]\n",
    "\n",
    "np.savez_compressed(\"data_oneclass_resnet_anormales.npz\", X=X_anormales, y=y_anormales, groups=groups_anormales)\n",
    "\n",
    "print(\"✅ Datasets guardados exitosamente.\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
