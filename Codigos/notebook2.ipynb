{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "9a5e99e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Cargar dataset original\n",
    "df = pd.read_csv('labels.csv', sep=';')\n",
    "labels = df.copy()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "91b558cb",
   "metadata": {},
   "source": [
    "Tomo solo 1 slice aleatorio por paciente"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "d3a5087a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- 1. Filtrar FB, FM, TM y tomar 1 slice aleatorio por paciente ---\n",
    "fb_df = labels[labels['type'] == 'FB'].groupby('uuid').sample(1, random_state=42)\n",
    "fm_df = labels[labels['type'] == 'FM'].groupby('uuid').sample(1, random_state=42)\n",
    "tm_df = labels[labels['type'] == 'TM'].groupby('uuid').sample(1, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "9bc8baea",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "# --- 2. Procesar los TB con slices central -20, central, central +20 ---\n",
    "tb_df = labels[labels['type'] == 'TB'].drop_duplicates(subset='uuid')\n",
    "\n",
    "# Suponiendo que tienes carpetas por uuid y que cada una contiene los slices numerados\n",
    "tb_final = []\n",
    "\n",
    "for _, row in tb_df.iterrows():\n",
    "    uuid = row['uuid']\n",
    "    \n",
    "    # Ruta a la carpeta de slices de ese paciente (ajusta según tu estructura)\n",
    "    carpeta = os.path.join('Experiments/', str(uuid))\n",
    "    \n",
    "    # Listar los archivos (asegúrate que sean solo los png de slices)\n",
    "    slices = sorted([int(f.split('.')[0]) for f in os.listdir(carpeta) if f.endswith('.dcm')])\n",
    "    \n",
    "    if len(slices) == 0:\n",
    "        continue  # Por seguridad\n",
    "\n",
    "    central = slices[len(slices) // 2]\n",
    "    \n",
    "    # Slices a elegir: central-30, central, central+30 (con control de bordes)\n",
    "    candidatos = set(slices)\n",
    "    \n",
    "    for s in [central - 30, central, central + 30]:\n",
    "        if s in candidatos:\n",
    "            tb_final.append({\n",
    "                'type': 'TB',\n",
    "                'uuid': uuid,\n",
    "                'slice': s,\n",
    "                'x': 0,  # Si no necesitas x e y en TB pon 0\n",
    "                'y': 0\n",
    "            })\n",
    "\n",
    "# Convertir a DataFrame\n",
    "tb_df_final = pd.DataFrame(tb_final)\n",
    "\n",
    "# --- 3. Concatenar todo ---\n",
    "labels_final = pd.concat([fb_df, fm_df, tm_df, tb_df_final], ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "142549e7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "type\n",
      "TB    45\n",
      "FB    35\n",
      "FM    35\n",
      "TM    14\n",
      "Name: count, dtype: int64\n",
      "Total final: 129 muestras\n"
     ]
    }
   ],
   "source": [
    "print(labels_final['type'].value_counts())\n",
    "print(f\"Total final: {labels_final.shape[0]} muestras\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "aa8ef024",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  type  uuid  slice  label\n",
      "0   FB  1009     76      1\n",
      "1   FB  1067    186      1\n",
      "2   FB  1219     57      1\n",
      "3   FB  1251    188      1\n",
      "4   FB  1280    100      1\n",
      "label\n",
      "1    70\n",
      "0    59\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# Crear la columna 'label': 1 si FB o FM, 0 si TB o TM\n",
    "labels_final['label'] = labels_final['type'].map(lambda x: 1 if x in ['FB', 'FM'] else 0)\n",
    "\n",
    "# Eliminar columnas 'x' y 'y'\n",
    "labels_final = labels_final.drop(columns=['x', 'y'])\n",
    "\n",
    "# Revisar que quedó bien\n",
    "print(labels_final.head())\n",
    "print(labels_final['label'].value_counts())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "6f08112d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    type  uuid  slice  label\n",
      "0     FB  1009     76      1\n",
      "1     FB  1067    186      1\n",
      "2     FB  1219     57      1\n",
      "3     FB  1251    188      1\n",
      "4     FB  1280    100      1\n",
      "..   ...   ...    ...    ...\n",
      "124   TB  6080    139      0\n",
      "125   TB  6080    169      0\n",
      "126   TB  6644     51      0\n",
      "127   TB  6644     81      0\n",
      "128   TB  6644    111      0\n",
      "\n",
      "[129 rows x 4 columns]\n"
     ]
    }
   ],
   "source": [
    "print(labels_final)\n",
    "labels_final.to_csv('labels_final.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "28e6f890",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import cv2\n",
    "import numpy as np\n",
    "import pydicom\n",
    "import pandas as pd\n",
    "\n",
    "def dcm_a_png(dcm_path, png_path, window_min=-1000, window_max=400):\n",
    "    try:\n",
    "        ds = pydicom.dcmread(dcm_path)\n",
    "        img = ds.pixel_array.astype(np.float32)\n",
    "        img = np.clip(img, window_min, window_max)\n",
    "        img = ((img - window_min) / (window_max - window_min)) * 255.0\n",
    "        img = img.astype(np.uint8)\n",
    "        os.makedirs(os.path.dirname(png_path), exist_ok=True)\n",
    "        cv2.imwrite(png_path, img)\n",
    "    except Exception as e:\n",
    "        print(f\"Error procesando {dcm_path}: {e}\")\n",
    "\n",
    "def convertir_df_dcm_a_png(df, input_dir='Experiments', output_dir='output_png',\n",
    "                           window_min=-1000, window_max=400):\n",
    "    for idx, row in df.iterrows():\n",
    "        uuid = row['uuid']\n",
    "        slice_num = row['slice']\n",
    "        dcm_file = os.path.join(input_dir, f\"{uuid}/{slice_num}.dcm\")\n",
    "        png_file = os.path.join(output_dir, f\"{uuid}/{slice_num}.png\")\n",
    "        if os.path.exists(dcm_file):\n",
    "            dcm_a_png(dcm_file, png_file, window_min, window_max)\n",
    "        else:\n",
    "            print(f\"No encontrado: {dcm_file}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "b1fa83a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "convertir_df_dcm_a_png(labels_final, input_dir='Experiments', output_dir='Experiments-png')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c72c336d",
   "metadata": {},
   "source": [
    "GLCM + LBP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "9c13ad45",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "from skimage.feature import local_binary_pattern\n",
    "from skimage.feature import graycomatrix, graycoprops\n",
    "from skimage.color import rgb2gray\n",
    "\n",
    "# ---------------- Configuración ---------------- #\n",
    "\n",
    "# Configuración de LBP\n",
    "radius = 1\n",
    "n_points = 8 * radius\n",
    "method = 'uniform'  # Da un histograma de 59 bins con 8 vecinos\n",
    "\n",
    "# Configuración de GLCM\n",
    "distances = [1]\n",
    "angles = [0, np.pi/4, np.pi/2, 3*np.pi/4]\n",
    "\n",
    "# ---------------- Función de extracción ---------------- #\n",
    "\n",
    "def extraer_features(img):\n",
    "    \"\"\"\n",
    "    Extrae características GLCM + LBP sobre toda la imagen.\n",
    "    Retorna: features_glcm, features_lbp, features_concatenados\n",
    "    \"\"\"\n",
    "    \n",
    "    if len(img.shape) == 3:\n",
    "        img = rgb2gray(img)\n",
    "    \n",
    "    img = (img * 255).astype(np.uint8)  # Asegurar escala de 0-255 si es float\n",
    "\n",
    "    # ------ GLCM Features ------ #\n",
    "    glcm = graycomatrix(img, \n",
    "                        distances=distances, \n",
    "                        angles=angles, \n",
    "                        levels=256, \n",
    "                        symmetric=True, \n",
    "                        normed=True)\n",
    "    \n",
    "    contraste = graycoprops(glcm, 'contrast').flatten()\n",
    "    homogeneidad = graycoprops(glcm, 'homogeneity').flatten()\n",
    "    energia = graycoprops(glcm, 'energy').flatten()\n",
    "    correlacion = graycoprops(glcm, 'correlation').flatten()\n",
    "    entropia = -np.sum(glcm * np.log2(glcm + 1e-10), axis=(0, 1)).flatten()\n",
    "\n",
    "    features_glcm = np.concatenate([contraste, homogeneidad, energia, correlacion, entropia])\n",
    "\n",
    "    # ------ LBP Features ------ #\n",
    "    lbp = local_binary_pattern(img, n_points, radius, method)\n",
    "    hist, _ = np.histogram(lbp.ravel(), \n",
    "                           bins=np.arange(0, n_points + 3),\n",
    "                           range=(0, n_points + 2))\n",
    "    hist = hist.astype(\"float\")\n",
    "    hist /= (hist.sum() + 1e-6)  # Normalización\n",
    "\n",
    "    features_lbp = hist\n",
    "\n",
    "    # ------ Vector final ------ #\n",
    "    features = np.concatenate([features_glcm, features_lbp])\n",
    "\n",
    "    return features_glcm, features_lbp, features\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4dc503e7",
   "metadata": {},
   "source": [
    "Crear la matriz"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "0deea4d9",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 129/129 [00:10<00:00, 12.32it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   glcm_feat_0  glcm_feat_1  glcm_feat_2  glcm_feat_3  glcm_feat_4  \\\n",
      "0  2987.199020  3228.768092  2054.245012  3304.448715     0.501893   \n",
      "1  1762.941154  2341.829382  1740.008164  2346.661586     0.544249   \n",
      "2  2499.043756  3024.646581  2426.883172  3254.103753     0.533793   \n",
      "3  7780.496201  8272.937167  7005.812867  8576.090043     0.222883   \n",
      "4  3358.162128  4028.171101  4295.801477  4770.171062     0.567026   \n",
      "\n",
      "   glcm_feat_5  glcm_feat_6  glcm_feat_7  glcm_feat_8  glcm_feat_9  ...  \\\n",
      "0     0.437208     0.485942     0.442947     0.236925     0.234076  ...   \n",
      "1     0.498127     0.535225     0.500700     0.360304     0.355159  ...   \n",
      "2     0.468999     0.501406     0.466401     0.282675     0.277729  ...   \n",
      "3     0.198182     0.221299     0.199584     0.112676     0.108759  ...   \n",
      "4     0.532282     0.546979     0.522355     0.404752     0.398929  ...   \n",
      "\n",
      "   lbp_hist_2  lbp_hist_3  lbp_hist_4  lbp_hist_5  lbp_hist_6  lbp_hist_7  \\\n",
      "0    0.030975    0.081432    0.155048    0.100048    0.057198    0.055553   \n",
      "1    0.029968    0.067574    0.138474    0.085327    0.049973    0.042618   \n",
      "2    0.024563    0.073368    0.164421    0.096798    0.049351    0.048931   \n",
      "3    0.043819    0.055950    0.089882    0.059284    0.046143    0.070377   \n",
      "4    0.021179    0.056141    0.127487    0.067692    0.033714    0.038136   \n",
      "\n",
      "   lbp_hist_8  lbp_hist_9  uuid  label  \n",
      "0    0.324535    0.106731  1009      1  \n",
      "1    0.431057    0.076584  1067      1  \n",
      "2    0.366749    0.092739  1219      1  \n",
      "3    0.258064    0.161999  1251      1  \n",
      "4    0.483791    0.078251  1280      1  \n",
      "\n",
      "[5 rows x 32 columns]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import cv2\n",
    "import pandas as pd\n",
    "from tqdm import tqdm  # Barra de progreso\n",
    "\n",
    "# ---------------- Configuración ---------------- #\n",
    "carpeta_png = 'Experiments-png/'  # Carpeta donde están los PNGs\n",
    "labels = pd.read_csv('labels_final.csv')  # Tu dataframe con columnas uuid, slice, label\n",
    "\n",
    "# Lista para guardar resultados\n",
    "lista_features = []\n",
    "\n",
    "# ---------------- Recorrido ---------------- #\n",
    "for idx, row in tqdm(labels.iterrows(), total=labels.shape[0]):\n",
    "    uuid = row['uuid']\n",
    "    slice_num = row['slice']\n",
    "    etiqueta = row['label']\n",
    "\n",
    "    ruta_imagen = os.path.join(carpeta_png, f\"{uuid}/{slice_num}.png\")\n",
    "    \n",
    "    if not os.path.exists(ruta_imagen):\n",
    "        print(f\"Advertencia: No se encontró {ruta_imagen}\")\n",
    "        continue\n",
    "\n",
    "    img = cv2.imread(ruta_imagen, cv2.IMREAD_GRAYSCALE)\n",
    "    if img is None:\n",
    "        print(f\"Error cargando {ruta_imagen}\")\n",
    "        continue\n",
    "\n",
    "    features_glcm, features_lbp, features_concatenados = extraer_features(img)\n",
    "    \n",
    "    # Guardar en lista con uuid, slice y label\n",
    "    lista_features.append([uuid, slice_num, etiqueta] + features_concatenados.tolist())\n",
    "\n",
    "# ---------------- DataFrame final ---------------- #\n",
    "\n",
    "# Solo necesitas definir columnas una vez, conociendo el tamaño de los vectores\n",
    "num_glcm = features_glcm.shape[0]\n",
    "num_lbp = features_lbp.shape[0]\n",
    "\n",
    "columnas_glcm = [f'glcm_feat_{i}' for i in range(num_glcm)]\n",
    "columnas_lbp = [f'lbp_hist_{i}' for i in range(num_lbp)]\n",
    "columnas = ['uuid', 'slice', 'label'] + columnas_glcm + columnas_lbp\n",
    "\n",
    "df_features = pd.DataFrame(lista_features, columns=columnas)\n",
    "\n",
    "# Eliminar columna slice\n",
    "df_features = df_features.drop(columns=['slice'])\n",
    "\n",
    "# Reordenar columnas\n",
    "columnas = [col for col in df_features.columns if col not in ['uuid', 'label']] + ['uuid', 'label']\n",
    "\n",
    "df_features = df_features[columnas]\n",
    "\n",
    "print(df_features.head())\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "d44dfef6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Archivo df-deepfake.npz guardado correctamente.\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "# Separar features, labels y uuids\n",
    "X = df_features.drop(columns=['uuid', 'label']).values\n",
    "y = df_features['label'].values\n",
    "uuids = df_features['uuid'].values\n",
    "\n",
    "# Guardar en formato comprimido\n",
    "np.savez_compressed(\"df-deepfake.npz\", X=X, y=y, uuids=uuids)\n",
    "\n",
    "print(\"Archivo df-deepfake.npz guardado correctamente.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "cf3baa5d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\JUAN\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\torchvision\\models\\_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
      "  warnings.warn(\n",
      "c:\\Users\\JUAN\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\torchvision\\models\\_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=ResNet18_Weights.IMAGENET1K_V1`. You can also use `weights=ResNet18_Weights.DEFAULT` to get the most up-to-date weights.\n",
      "  warnings.warn(msg)\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torchvision.models as models\n",
    "import torchvision.transforms as transforms\n",
    "from PIL import Image\n",
    "import numpy as np\n",
    "import os\n",
    "\n",
    "\n",
    "# ---------------- Configuración ---------------- #\n",
    "\n",
    "# Cargar ResNet preentrenada\n",
    "resnet = models.resnet18(pretrained=True)  # Puedes usar resnet34, resnet50, etc.\n",
    "resnet.eval()  # Modo evaluación\n",
    "\n",
    "# Quitar la capa final (clasificación) para quedarte solo con los features\n",
    "feature_extractor = torch.nn.Sequential(*list(resnet.children())[:-1])\n",
    "\n",
    "# Transformaciones necesarias para la imagen\n",
    "transform = transforms.Compose([\n",
    "    transforms.Resize((224, 224)),  # Las redes esperan 224x224\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=[0.485, 0.456, 0.406],  # ImagenNet stats\n",
    "                         std=[0.229, 0.224, 0.225])\n",
    "])\n",
    "\n",
    "# ---------------- Función para extraer features ---------------- #\n",
    "\n",
    "def extraer_features_resnet(ruta_img):\n",
    "    img = Image.open(ruta_img).convert('RGB')  # Convertir a RGB (aunque sea CT, se duplican canales)\n",
    "    img = transform(img).unsqueeze(0)  # Añadir batch dimension\n",
    "    with torch.no_grad():\n",
    "        features = feature_extractor(img).squeeze().numpy()  # shape: (512,)\n",
    "    return features\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "48e1a37b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Shape final X: (129, 512)\n",
      "✅ Shape final y: (129,)\n",
      "✅ Shape final groups: (129,)\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torchvision.models as models\n",
    "import torchvision.transforms as transforms\n",
    "from PIL import Image\n",
    "import numpy as np\n",
    "import os\n",
    "\n",
    "\n",
    "\n",
    "# Función de extracción\n",
    "def extraer_features_resnet(ruta_img):\n",
    "    img = Image.open(ruta_img).convert('RGB')\n",
    "    img = transform(img).unsqueeze(0)\n",
    "    with torch.no_grad():\n",
    "        features = feature_extractor(img).squeeze().numpy()\n",
    "    return features\n",
    "\n",
    "# Leer CSV\n",
    "labels = pd.read_csv(\"labels_final.csv\")  # Asegúrate que se llama así\n",
    "\n",
    "# Listas para guardar\n",
    "features_lista = []\n",
    "labels_lista = []\n",
    "groups_lista = []\n",
    "\n",
    "carpeta_png = \"Experiments-png/\"\n",
    "\n",
    "# Recorrido basado en el CSV\n",
    "for idx, row in labels.iterrows():\n",
    "    uuid = str(row['uuid'])\n",
    "    slice_num = str(row['slice'])\n",
    "    label = row['label']\n",
    "\n",
    "    ruta_img = os.path.join(carpeta_png, uuid, f\"{slice_num}.png\")\n",
    "\n",
    "    if not os.path.exists(ruta_img):\n",
    "        print(f\"⚠ No se encontró {ruta_img}\")\n",
    "        continue\n",
    "\n",
    "    features = extraer_features_resnet(ruta_img)\n",
    "    features_lista.append(features)\n",
    "    labels_lista.append(label)\n",
    "    groups_lista.append(uuid)\n",
    "\n",
    "# Convertir a arrays\n",
    "X = np.array(features_lista)\n",
    "y = np.array(labels_lista)\n",
    "groups = np.array(groups_lista)\n",
    "\n",
    "print(f\"✅ Shape final X: {X.shape}\")\n",
    "print(f\"✅ Shape final y: {y.shape}\")\n",
    "print(f\"✅ Shape final groups: {groups.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "7a21aaf1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Archivo 'features_labels_resnet.npz' guardado exitosamente.\n"
     ]
    }
   ],
   "source": [
    "# Guardar como archivo comprimido\n",
    "np.savez_compressed(\"features_labels_resnet.npz\", X=X, y=y, groups = groups)\n",
    "\n",
    "print(\"✅ Archivo 'features_labels_resnet.npz' guardado exitosamente.\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
